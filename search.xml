<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>UE中的各种depth的解释及应用</title>
      <link href="/2020/04/21/explanation-on-depth-in-unreal/"/>
      <url>/2020/04/21/explanation-on-depth-in-unreal/</url>
      
        <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>有时候我们在绘制透明的人物角色时，既想要其透明，又想要有一个基于fresnel的边缘光。直接写出来的材质会遇到透明面的穿插交叠的问题。如<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/0_wrong_translucent_object.png" alt title><br>本文会在解决这个问题的同时，对UE4中的scene depth, pixel depth和custom depth这三个容易混淆的概念做个解释和备注。<br><a id="more"></a></p><h1 id="三种depth比较"><a href="#三种depth比较" class="headerlink" title="三种depth比较"></a>三种depth比较</h1><h2 id="Custom-Depth"><a href="#Custom-Depth" class="headerlink" title="Custom Depth"></a>Custom Depth</h2><p>默认情况下不会启用，但是用户有选择性的向其写入深度，从而实现一些复杂的效果。<br>首先在对象面板上勾选Render Custom Depth Pass，这样就能将该物体的深度信息写入custom depth buffer了。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/2.1_render_customdepth_checkbox.png" alt title><br>这里需要注意，对于透明物体，如果直接开启Render CustomDepth Pass是没有作用的，还需要在对应的材质编辑器的属性面板上勾选<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/2.2_allow_customdepth_checkbox.png" alt title></p><p>查看custom buffer如下图<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/2.3_customdepth_first_view.png" alt title></p><p>它的工作原理我们可以做个试验，在透明的人物前面放一个不透明的cube，用的是默认opaque的材质，但同样写入custom depth。<br>然后设置透明的人物材质，设定一个CloseDepthThreshold，当深度小于这个值的时候，显示白色，大于这个值的时候显示黑色。将其连接到Emissive color，并将Opacity设为1这样比较方便观察。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/2.4_customdepth_nodes.png" alt title><br>另外记得要禁用透明材质的深度测试，这样我们可以强制透明材质最后绘制的时候覆盖已有的custom depth buffer.否则因为遮挡关系，我们没法看到cube背后的部分。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/2.5_disable_depth_test.png" alt title><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/2.6_customdepth_result.png" alt title><br>因为关闭了translucent材质的深度测试，所以透明人物绘制在最顶层。可以看到，头部和手部因为比较靠近相机，所以绘制了出来。但本来较远的腹部也显示了出来，这是因为透明材质shader中使用的是cube的custom depth信息，所以深度小于显示的阈值。<br>也即说明，custom depth是一个buffer，较小的值会覆盖较大的值。</p><h2 id="Pixel-Depth"><a href="#Pixel-Depth" class="headerlink" title="Pixel Depth"></a>Pixel Depth</h2><p>作为对比，如果将比较的对象设置为PixelDepth，则会有不一样的结果<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/2.7_pixeldepth_nodes.png" alt title><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/2.8_pixeldepth_result.png" alt title></p><p>可以看到到，透明人物采用的还是其自己的深度信息，也即是说因为关闭了depth test，所以它覆盖了本来的cube在pixel depth buffer中的信息。如果开启了depth test且将cube关闭render in main pass（防止不透明的物体挡住后面的人物），则会得到相同的结果。</p><h2 id="Scene-Depth"><a href="#Scene-Depth" class="headerlink" title="Scene Depth"></a>Scene Depth</h2> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/2.9_scenedepth_nodes.png" alt title><p>首先cube将自己的深度写入了scene dpeth buffer，而透明人物因为是translucent的缘故，zwrite关闭，所以depth buffer中完全没有人物的深度信息。因此只能绘制出被cube遮挡处的部分。<br>Tip:对于opaque的物体，它无法读取scene depth，所以只能直接用pixel depth。<br>对于post-processing，它不能使用pixel depth，使用scene depth和SceneTexture:SceneDepth基本等价，除了后者可能会因为抗锯齿而有抖动<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/2.10_pixeldepth_result.png" alt title></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>首先默认物体都打开了render to custom depth，透明物体也打开了allow custom depth write。<br>如果场景内只有一个物体，且物体本身没有自我交叠，则custom depth == pixel depth。若物体是opaque的，则scene depth未定义；若物体是translucent，则scene depth为原始状态<br>如果场景中只有一个物体，物体本身有交叠。若物体是opaque的，则custom depth == pixel depth；若是translucent的，则custom depth &lt;= pixel depth，其中靠近摄像机的一面custom depth == pixel depth，背面的custom depth &lt; pixel depth。scene depth情况同上。<br>如果场景中有两个物体，不透明的物体挡在另一个不透明物体前面。如果不透明物体没有写入custom depth，则custom depth &lt;= pixel depth。<br>如果是不透明的物体挡在透明物体前面，因为后期特效中无法使用pixel depth，scene depth因为是透明物体，也没有写入，所以能比较的只有不透明物体，也就没有意义了。<br>还有其他很多中情况这里就不一一列举了。需要仔细思考情况再加以判断。</p><p>测试中，我们将整体透明度改为0.5，这样可以看到背面的部分<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/2.11_backface_fade.png" alt title></p><p>可以看到后侧的mesh因为pixel depth超过阈值，所以显示黑色，最终显示出来的是前半部分，深度较小的部分。这也可以说明，pixel depth可以采样到被遮挡的部分，并不是使用一个类似buffer的机制来存储的（可能是利用顶点插值的深度？）</p><h1 id="避免重复绘制半透部分"><a href="#避免重复绘制半透部分" class="headerlink" title="避免重复绘制半透部分"></a>避免重复绘制半透部分</h1><p>有了前面的结论，我们首先对custom depth 和pixel depth进行比较。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/3.1_pixel_custom_depth_compare_nodes.png" alt title><br>如果这里depth bias为0，根据我们上面的结论，custom depth &lt;= pixel depth，所以应该不透明度始终为0。结果也的确如此<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/3.2_no_bias_compare_result.png" alt title></p><p>因此，我们需要将pixel增加一个小的负的偏移值，即相当于将pixel depth朝相机方向移动一点。对于正面的部分来说，就是可以将其显示出来。而对于背面来说，因为移动了之后还是没法比正面更靠近相机（背面部分pixel depth &gt; custom depth），所以不透明度依然为0。从而我们就达到了去掉重叠部分的目的。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/3.3_bias_compare_result.png" alt title></p><p>可以看到有些分割处还是会有重叠的显现。这是因为他们的前后面的深度差太小，depth bias已经大于他们的深度差了，所以背面也显示出来了，即更亮了。<br>当这个bias大到一定程度之后，就是完全的重叠显现了<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/3.4_over_bias_compare_result.png" alt title></p><h1 id="绘制半透勾边人物"><a href="#绘制半透勾边人物" class="headerlink" title="绘制半透勾边人物"></a>绘制半透勾边人物</h1><p>上面一步操作可以让我们避免重复绘制mesh，我们回到一开始的地方，再次尝试绘制透明角色。<br>我们这里的描边是通过修改不透明度opacity来实现的（越边缘处，不透明度越高）<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/4.1_translucent_nodes.png" alt title></p><p>这时只想显示透明物体的轮廓时也不奏效了。因为我们用到了fresnel，虽然它只画了一次，但是因为背面没有被剔除，所以背面的转折处依旧被赋予了一个高opacity，从而显示了出来。（我们第一步做的操作只是让前后的mesh“不会”绘制两次，但是计算fresnel的时候，我们并没有办法剔除它们）因此，我们还要想办法把背面剔除<br>解决方法是我们需要用另一个不透明物体放置在同一个位置上，render custom depth且关闭render in main pass。这样不透明的物体就能即写入深度，从而让透明物体背面的部分被剔除。<br>最终的效果图如下<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/4.2_result_1.png" alt title><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/explanation_on_depth_in_unreal/4.3_result_2.png" alt title></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.tomlooman.com/the-many-uses-of-custom-depth-in-unreal-4/" target="_blank" rel="noopener">[1]Custom Depth in Unreal Engine 4</a><br><a href="https://www.cnblogs.com/litmin/p/6802204.html" target="_blank" rel="noopener">[2]UE4 custom depth 自定义深度</a><br><a href="https://www.wxwenku.com/d/100311983" target="_blank" rel="noopener">[3]开发者遇到的典型美术相关问题回顾</a><br><a href="https://blog.csdn.net/qq_16756235/article/details/78303695" target="_blank" rel="noopener">[4]虚幻4中SceneDepth , PixelDepth ,Customdepth,CustomDepth StencilValue的区别</a><br><a href="https://blog.csdn.net/qq_16756235/article/details/76616408" target="_blank" rel="noopener">[5]两个重叠模型模拟双pass,顺便解决透明乱序问题</a><br><a href="https://superyateam.com/2019/06/17/custom-depth-and-custom-depth-stencil-in-ue4/" target="_blank" rel="noopener">[6]Custom Depth and Custom Depth Stencil in UE4</a><br><a href="https://www.hanzhe.com/article/17" target="_blank" rel="noopener">[7]UE4材质中的PixelDepth和SceneDepth</a></p>]]></content>
      
      
      <categories>
          
          <category> Dev </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shader </tag>
            
            <tag> game </tag>
            
            <tag> vfx </tag>
            
            <tag> unreal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pixel shader中的翻页动画</title>
      <link href="/2020/04/12/page-curl/"/>
      <url>/2020/04/12/page-curl/</url>
      
        <content type="html"><![CDATA[ <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/0_page_curl.gif" alt title><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>有时候，我们在游戏中需要表现一个书本打开或则翻页的效果。如果很生硬的用一个2D形变动画或者一个淡入淡出，那肯定达不到想要的效果。所以有人想到了用3D UI来制作动画。W.Dana Nuon<a href="#ref">[1]</a>有一篇文章介绍了一种将2D坐标映射到3D空间来完成一个基于圆锥的翻页顶点动画。由于是顶点动画，所以平面需要进行细分，顶点越多，自然效果也越好。可是有时候，这个需求只是做在UI中的，他们可能没有必要的3D美术或者制作3D UI的经验。他们只能制作2D的素材。这种时候该怎么办呢？<br>本文中将会提出一种基于片段着色器的方法，在屏幕空间下模拟翻页的动画。本质上其实就是一个ray-tracing的过程，只不过很多地方都进行了化简和hack</p><a id="more"></a><h1 id="利用光线追踪"><a href="#利用光线追踪" class="headerlink" title="利用光线追踪"></a>利用光线追踪</h1><p>普通的渲染过程是光栅化，它将集合体上的每一个顶点对应到屏幕的对应位置，然后对其中的每个像素进行光栅化插值。其中发生的变化过程是将坐标从3D投影到2D上。这是一个简单但也高效的过程。早些时候，基本上所有的渲染都是利用光栅化的手段进行渲染的。<br>但对于我们这里的例子，我们正是因为没有办法求得3D坐标，所以无法展现这个动态过程，所以我们需要找寻另一种渲染的方式。也即ray-tracing的方法。<br>我们定义一个虚拟的摄像机坐标系，其中x正方向指向右侧，y正方向指向下侧（因为UE4中uv的v是自顶向下，所以我们这么定义方向，对于unity，我们也可以反过来），z轴垂直纸面向外。摄像机（或者说观察点）位于屏幕裁面（纸面）外，指向纸面（即z轴负方向）。对于一个quad，因为原始的uv的范围是[0,1]，为了方便起见，我们把它划分为两块，如下图所示，再将虚拟”摄像机”安放在(0,0.5,5)的位置<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/2.1_coordinate.png" alt title><br>我们假设摄像机的投影面即为xy范围[-1, 0]到[1, 1]，z为0的平面。我们若想知道这个quad上某个像素应该着什么颜色，只用从摄像机向近裁面上该点射一道射线，和物体的交点的颜色值即为绘制的颜色。<br>按照上面的定义我们可以知道，初始状态下，每个像素点的xy坐标即为纹理采样中的uv坐标。如果我们将左右两张贴图分别放在了[-1,0]-[0,1]和[0,0]-[1,1]的范围内，则可能还要重新映射一下左侧的贴图。<br>至此，我们就有了基本的框架</p><h1 id="平板翻页"><a href="#平板翻页" class="headerlink" title="平板翻页"></a>平板翻页</h1><p>在进行更复杂的翻页之前，我们先来实现一种最简单的翻页效果。想象我们的纸是一个刚性的片，翻页的过程中只有角度的变化。我们只用进行一个ray-plane intersection测试就知道，观察视线和quad的交点的3D坐标。<br>射线的表达式为：<br>$$E+t\vec{EP} = T \qquad (1)$$<br>平面的表达式：<br>$$dot(\vec{N}, T) = 0$$<br>即$$\vec{N}_x . T_x + \vec{N}_y . T_y + \vec{N}_z . T_z = 0 \qquad (2)$$<br>其中E是摄像机的位置，P是投影面上的采样点坐标，T是纸片上的交点坐标，$\vec{EP}$是观察方向，N是纸片法线方向（假设纸片绕着y轴正方向，按照右手坐标系旋转了$\theta$弧度，则$\vec{N} = (-sin\theta, 0, cos\theta)$）<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/3.1_plane_normal.png" alt title><br>E,D,P,N都已知，两式联立起来，将$E+t\vec{EP}$代入2式的T，就可以解出t，<br>$$-sin(\theta)(E_x + t{EP}_x) + cos(\theta)(E_z + t{EP}_z) = 0$$<br>$$ t = \frac{(E_z - tan(\theta)E_x)}{(tan(\theta){EP}_x - {EP}_z)}$$<br>由 $E+t\vec{EP} = T $ 从而求出T</p><p>T的$T_x$和$T_y$是我们所关注的，但它们是z=0的平面上的投影坐标，而不是采样时用到的uv坐标。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/3.2_flat_perspective.png" alt title><br>对于$T_v$，它等于$T_y$，因为我们并没有在y方向上进行移动。而对于$T_u$，因为已经知道了OT的长度，也知道了$T_y$，所以用勾股定律就可以求得<br>$$T_{u} =\sqrt{OT^{2} -(T_{v} )^{2}}$$</p><p>有了uv坐标，自然就能知道该像素该绘制的颜色。最终效果如下<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/3.3_flat_rolling.gif" alt title="备注：这里x负半轴的u已经翻转过了，如果未处理，则应该绕y轴对称"></p><h1 id="增加一些弧度"><a href="#增加一些弧度" class="headerlink" title="增加一些弧度"></a>增加一些弧度</h1><p>如果用平板翻页，虽然视觉上是真实了，但是物理上还是失真。因为现实中纸张都比较柔软，在翻页的时候会褶皱或者弯曲。所以我们需要用另一种方法去模拟这个弯曲弧度。<br>这里用到的一个思路是，假想纸片包裹在一个过y轴且轴线平行于y轴的圆柱体。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/4.1_ray_cylinder.png" alt title></p><h2 id="射线与圆柱相交测试"><a href="#射线与圆柱相交测试" class="headerlink" title="射线与圆柱相交测试"></a>射线与圆柱相交测试</h2><p>第一步还是求交点T，这次是ray-cylinder。不过在这里因为y方向不重要，所以我们可以只考虑xz平面，将问题化简成ray-cycle相交的问题<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/4.2_ray_cycle.png" alt title><br>射线的表达式为：<br>$$E+t\vec{EP} = T$$<br>平面的表达式：<br>$$(T - C)^2 = r^2$$<br>这里所有向量都用2D向量表示。r为我们自定义的圆柱（圆）的半径，为已知量。<br>这里还有个细节，就是C的位置。C是圆心的坐标。在初始状态下，它的xz平面横坐标应该为$(0.5, -\sqrt{r^{2} -(0.5)^{2}})$<br>随着圆柱旋转起来，它的坐标还要再用一个2D的旋转矩阵来更新<br>求得C之后，将两式联立起来就是<br>$$(E+t\vec{EP} - C)^2 = r^2$$<br>$$\Longrightarrow (\vec{CE}+t\vec{EP})^2 = r^2$$<br>$$( CE_{x} +tEP_{x})^{2} +( CE_{z} +EP_{z})^{2} =r^{2}$$<br>$$t^{2}(EP_{x}^2 + EP_{z}^2) + 2t(CE_{x}.EP_{x} +CE_{z}.EP_{z}) +(CE_{x}^2 + CE_{z}^2) - r^2=0$$<br>于是利用一元二次方程$ax^2+bx+c=0$的求根公式求解t<br>$$<br>\begin{cases}<br>a = (EP_{x}^2 + EP_{z}^2)\\<br>b = 2( CE_{x} .EP_{x} +CE_{z} .EP_{z})\\<br>c = (CE_{x}^2 + CE_{z}^2) - r^2<br>\end{cases}<br>$$<br>t可能有1解，2解或者无解，分别对应相切，相交，相离三种情况<br>对于有2解的情况（即$\Delta = b^2 - 4ac &gt; 0$），我们令<br>$$<br>\begin{cases}<br>t1 = \frac{-b-\sqrt{b^{2} -4ac}}{2a}\<br>t2 = \frac{-b+\sqrt{b^{2} -4ac}}{2a}<br>\end{cases}<br>$$<br>t1,t2分别对应近交点T1和远交点T2。当我们要决定如何绘制像素的颜色时，也是从这两个值中选择一个作为uv的依据</p><p>先考虑T为T1的情况，假设射线先交在T1处，于是我们想知道它对应的uv坐标。这次的v还是和前面flat时候的例子一样$T_v = T_y$<br>但对于$T_u$我们无法直接求得，要首先通过CO和CT的dot（因为$\angle OCT(\alpha)$的范围是[0,π]）求出角$\alpha$，再利用$\angle \alpha$的弧长来得到$T_u$<br>$$dot(CO, CT) = r^2 * cos\alpha$$</p><p>代码如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">float2 uv = ((in_uv.x - <span class="number">0.5</span>)*<span class="number">2</span>, in_uv.y);</span><br><span class="line">float3 P = float3(uv, <span class="number">0</span>);</span><br><span class="line">float3 EP = normalize(P - E);</span><br><span class="line"></span><br><span class="line">float3 chord_normal = float3(-<span class="built_in">sin</span>(theta), <span class="number">0</span>, <span class="built_in">cos</span>(theta));</span><br><span class="line">float3 A = float3(<span class="built_in">cos</span>(theta), <span class="number">0</span>, <span class="built_in">sin</span>(theta))<span class="comment">// The right edge projected point on xz plane</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Get intersection on cylinder</span></span><br><span class="line">float3 E = float3(<span class="number">0</span>, <span class="number">0.5</span>, <span class="number">5</span>); <span class="comment">// eye position</span></span><br><span class="line"><span class="keyword">float</span> r = <span class="number">1</span> / curvature; <span class="comment">// r is AC</span></span><br><span class="line"><span class="keyword">float</span> AM = <span class="number">0.5</span>;</span><br><span class="line"><span class="keyword">float</span> MC = <span class="built_in">sqrt</span>(r*r - AM * AM);</span><br><span class="line">float3 C = (A + <span class="number">0</span>)*<span class="number">0.5</span> <span class="comment">// M is the midpoint of AO</span></span><br><span class="line">float3 CE = E - C;</span><br><span class="line"></span><br><span class="line"><span class="keyword">float</span> a = EP.x*EP.x + EP.z*EP.z;</span><br><span class="line"><span class="keyword">float</span> b = <span class="number">2</span>(CE.x*EP.x + EP.z*CE.z);</span><br><span class="line"><span class="keyword">float</span> c = CE.x*CE.x + CE.z*CE.z - r*r;</span><br><span class="line"><span class="keyword">float</span> delta = b*b - <span class="number">4</span>*a*c;</span><br><span class="line"></span><br><span class="line"><span class="keyword">float</span> t1 = (-b - delta) / (<span class="number">2</span>*a);</span><br><span class="line"><span class="keyword">float</span> t2 = (-b + dleta) / (<span class="number">2</span>*a);</span><br><span class="line"></span><br><span class="line">float3 T1 = E + t1*EP;</span><br><span class="line">float3 T2 = E + t2*EP;</span><br></pre></td></tr></table></figure></p><p>这样我们就能正确的采样纹理了。这一步完成之后，我们可以测试不同曲率半径下的表现<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/4.3_curvature_change.gif" alt title="这个时候应该已经可以感受到圆柱的体积了"></p><h2 id="旋转圆柱体"><a href="#旋转圆柱体" class="headerlink" title="旋转圆柱体"></a>旋转圆柱体</h2><p>接下来，我们将圆柱体绕着y轴旋转$\theta$角度<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/4.5_cycle_rotation_topdown.png" alt title><br>效果如下<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/4.4_rolling_cylinder.gif" alt title><br>我们还可以debug交点T1,T2的深度变化情况<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/4.6_t1_z.gif" alt title><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/4.7_t2_z.gif" alt title><br>但这个真实的卷纸还有些差别，卷纸虽然依附于圆柱体上，但是只有部分是显示的，即我们要对圆柱进行裁剪。裁剪的依据是判断uv坐标是否落在了[0,1]的区间内。对u大于1或者小于0的部分，我们则不绘制。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/4.8_cycle_rotation_1.png" alt title><br>不过有时候虽然u在[0,1]中，但是面却是背面，如下图所示。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/4.9_cycle_rotation_2.png" alt title><br>所以只有当uv在[0,1]中且视线与圆柱的正面相交，才能说明当前采样点属于正面。<br>我们可以得到正面的部分的mask动画，即上图中斜向的网格线区域<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/4.10_front_face_mask.gif" alt title><br>接下来，如果剩余的黑色区域中与圆柱体有交点，则应该绘制背面<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/4.11_look_through.png" alt title="这里u轴负半轴的部分也被剔除了，因为它的u没有在[0,1]的区间里"><br>相关代码如下:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Sample on texture from 3d position: T</span></span><br><span class="line"><span class="function">float4 <span class="title">GetUv</span><span class="params">(float3 T, float3 C, float3 E, out float2 uv_1st)</span> </span>&#123;</span><br><span class="line">    float2 CT = float2(T.x, T.z) - float2(C.x, C.z);</span><br><span class="line">    float2 TE = float2(E.x, E.z) - float2(T.x, T.z);</span><br><span class="line">    <span class="keyword">float</span> face = sign(dot(CT, TE));</span><br><span class="line"></span><br><span class="line">    float2 CO = - float2(C.x, C.z);</span><br><span class="line">    <span class="keyword">float</span> cos_alpha = dot(CT, CO)/(r*r);</span><br><span class="line">    <span class="keyword">float</span> sample_u = arccos(cos_alpha);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Check if u is on the positive side or not</span></span><br><span class="line">    <span class="keyword">float</span> is_positive = sign(CT.x*CO.y - CT.y*CO.x); <span class="comment">// 2D cross product</span></span><br><span class="line">    sample_u = sample_u * is_positive; <span class="comment">// now u is mapped to [-1,0] and [0,1]</span></span><br><span class="line">    float2 origin_uv = float2(sample_u, T.y);</span><br><span class="line">    float2 stage1_uv = origin_uv * float2(sign(dir), <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">float</span> face_dir = sign(face * dir);</span><br><span class="line">    float2 stage2_uv = face_dir &gt; <span class="number">0</span> ? stage1_uv: float2(<span class="number">1</span> - stage1_uv.x, stage1_uv.y);</span><br><span class="line">    <span class="keyword">float</span> IsUvValid = (stage1_uv.x &gt; <span class="number">0</span> &amp;&amp; stage1_uv.x &lt; u_limit &amp;&amp; stage1_uv.y &gt; <span class="number">0</span> &amp;&amp; stage1_uv.y &lt; <span class="number">1</span>) ? <span class="number">1</span>:<span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> float3(stage2_uv, IsUvValid, face);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">float2 T1_1st_uv, T2_1st_uv;</span><br><span class="line">float4 T1_uv = GetUv(T1, C, E, T1_1st_uv);</span><br><span class="line">float4 T2_uv = GetUv(T2, C, E, T2_1st_uv);</span><br><span class="line">float2 overlap_uv = T1_uv.z &gt; <span class="number">0</span> ? T1_uv.xy : T2_uv.xy;</span><br><span class="line"><span class="comment">// Get stage1 uv that centered at mid so that we can apply x_limit later correctly</span></span><br><span class="line">float2 overlap_1st_uv = T1_uv.z &gt; <span class="number">0</span> ? T1_1st_uv.xy : T2_1st_uv.xy;</span><br><span class="line"><span class="keyword">float</span> overlap_face = T1_uv.z &gt; <span class="number">0</span> ? T1_uv.w : T2_uv.w;</span><br><span class="line"><span class="keyword">float</span> T_z = T1_uv.z &gt; <span class="number">0</span> ? T1.z : T2.z;</span><br></pre></td></tr></table></figure></p><p>完整的动画如下<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/4.12_rolling_cylinder_through.gif" alt title></p><h2 id="处理AB面"><a href="#处理AB面" class="headerlink" title="处理AB面"></a>处理AB面</h2><p>所谓AB面，即单数页(A)和偶数页(B)，分布在摊开书的左侧和右侧。我们将一页纸从右侧翻到左边的时候，需要用另一个面来绘制。这里有个需要注意的地方，如果右侧的书的边界是贴着左侧的，那翻过来之后就是贴着右侧了，但是u的方向不能简单镜像，因为那样会让字都反过来。<br>因为书页既可能从右翻到左，也可能从左翻到右。由由于翻的方向不同，其实我们需要虚拟出的圆柱体的方向也有所不同，如果是从右向左，圆柱体应该是轴线在初始状态（θ为0）的时候是在z轴负半轴。反之，如果从左向右，则在z轴正半轴。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/4.13_ab_pages.png" alt title></p><p>所以我们总共需要考虑4种情况。<br>我们校正uv可以分为两步：<br>1.根据指外翻还是内翻（即从右向左还是从左向右），将当前可见页的u重新映射到[0,1]的区间里<br>2.如果是B面（即观察方向和面的方向相反），将u做one minus取补。（例如[0,1]-&gt;[1,0]）<br>为方便比较，直接画出下面的表格<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/4.14_uv_stages.png" alt title="绿色代表当前显示页"><br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Switch left page or right page</span></span><br><span class="line"><span class="keyword">float</span> IsLeft = sign(overlap_face * dir);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Sampled texure color</span></span><br><span class="line">float4 sampled_color = IsLeft? tex2D(leftTex, overlap_uv):tex2D(rightTex, overlap_uv);</span><br><span class="line"><span class="comment">// Check if intersect uv is on the left(positive) side and in [0,1]</span></span><br><span class="line"><span class="keyword">float</span> current_page_mask = (</span><br><span class="line">    overlap_1st_uv.x &gt; <span class="number">0</span> &amp;&amp; overlap_1st_uv.x &lt; x_limit</span><br><span class="line">    &amp;&amp; overlap_1st_uv.y &gt; <span class="number">0</span> &amp;&amp; overlap_1st_uv.y &lt; <span class="number">1</span>) ? <span class="number">1</span>:<span class="number">0</span>;</span><br><span class="line">sampled_color = sampled_color * current_page_mask; <span class="comment">// Show only the current page</span></span><br><span class="line">sampled_color = float4(lerp(base_color.rgb, sampled_color.rgb, IsLeft), sampled_color.a);</span><br></pre></td></tr></table></figure></p><p>完成这一步之后，我们就能将正确的uv绘制出来了。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/4.15_1st_stage_valid_uv.gif" alt title="这里画出了等高线方便debug"></p><h1 id="自动曲率"><a href="#自动曲率" class="headerlink" title="自动曲率"></a>自动曲率</h1><p>我们在纸翻到一般，立于纸面的时候，希望曲率半径小一些（曲率大一些），而在靠近纸面处曲率半径大一些（曲率小一些）。我们可以绘制以下类似函数，从而实现动态自动调整弧度<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/page_curl/5.1_auto_curvature_graph.png" alt title><br>我使用的是上边红色的函数曲线，主要是多了一点小变化。如果要简化，用下面的函数也没问题。</p><h1 id="添加活页扣"><a href="#添加活页扣" class="headerlink" title="添加活页扣"></a>添加活页扣</h1><p>为了让书本更有趣，有时候会想加上一个活页的结构。因为活页扣比纸面高，所以它的处理需要额外处理一下。不过因为我们前面已经取得了大部分的坐标信息。所以到这一步的时候，我们只用比价一下深度就能知道绘制次序了。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Ring-binder</span></span><br><span class="line"><span class="keyword">float</span> occlude_mask = saturate(sign(ring_height - T_z));</span><br><span class="line">float4 ring_color = tex2D(RingTex, ring_uv);</span><br><span class="line"></span><br><span class="line"><span class="keyword">float</span> opacity = max(base_color.a, sampled_color.a);</span><br><span class="line">float4 final_color = float4(</span><br><span class="line">    lerp(sampled_color.rgb, ring_color.rgb, ring_color.a * occlude_mask),</span><br><span class="line">    opacity);</span><br></pre></td></tr></table></figure></p><p><span id="ref"></span></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://wdnuon.blogspot.com/2010/05/implementing-ibooks-page-curling-using.html" target="_blank" rel="noopener">[1] Implementing iBooks page curling using a conical deformation algorithm</a><br><a href="http://www2.parc.com/istl/groups/uir/publications/items/UIR-2004-10-Hong-DeformingPages.pdf" target="_blank" rel="noopener">[2] Turning Pages of 3D Electronic Books [Lichan Hong et al. 2003]</a><br><a href="http://lousodrome.net/blog/light/2017/01/03/intersection-of-a-ray-and-a-cone" target="_blank" rel="noopener">[3] Intersection of a ray and a cone</a></p>]]></content>
      
      
      <categories>
          
          <category> Dev </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graphics </tag>
            
            <tag> shader </tag>
            
            <tag> game </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>通过vertex split实现progressive mesh</title>
      <link href="/2020/03/28/vertex-split-operator/"/>
      <url>/2020/03/28/vertex-split-operator/</url>
      
        <content type="html"><![CDATA[ <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/vertex_split_operator/0.1_collapse_and_split.png" alt title="from Progressive Meshes[1]"><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>在上一篇文章中，我们依据高斯曲率对mesh进行平滑。但是由于平滑过程中经常会出现过多顶点聚集在一起的情况。另外，对很多顶点做平滑本身也是个相当耗时的操作。所以自然而然的，我们希望减少需要处理的顶点。虽然我们已经有了edge collapse（使用案例见<a href="/2020/03/07/mesh_quadric_downsampling">使用Quadric Error Metrics进行mesh简化</a>）但是光化简模型并做平滑本事并没有意义，毕竟我们损失了许多顶点信息。我们真正想做的事情是先减少顶点数-&gt;进行平滑操作-&gt;再还原出原本那些被删去的顶点，从而还原出整个拓扑结构。<br>所以，我们需要找出edge collapse的逆操作：vertex split——从一个顶点裂出一条边的两个顶点，并将原来连接至一个顶点的相邻边和点按照原本的结构连接到新的两个顶点上。</p><p>关于这个操作的概念，最早是伴随着Hugues Hoppe的Progressive Meshes<a href="#ref">[1]</a>一文一起提出的。它提出一个progress mesh序列可以表示为从$M^n$到$M^0$的过程,$M^n$即为原始模型，$M^0$则是经过n次edge collapse后化简的模型。这个序列也是可逆的。可以用下面两个过程来表示<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/vertex_split_operator/1.2_collapse_sequence.png" alt title><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/vertex_split_operator/1.3_split_sequence.png" alt title></p><a id="more"></a><h1 id="回顾edge-collapse"><a href="#回顾edge-collapse" class="headerlink" title="回顾edge collapse"></a>回顾edge collapse</h1><p>Hoppe使用的是VF的链表结构，即只存取保存顶点id的面序列。不过我们使用的half-edge，所以接下来的叙述，我都会以half-edge为背景叙述。<br>在实现这个operator之前，我们首先要确定它所需要的信息。对于edge collapse操作，它会减去一条边和一个顶点，还会合并中间的边两侧的边（如果我们事先已处理过模型成为triangulated mesh，只包含三角面）（作图！！！）。所以首先我们要记录原始的两个顶点的id和位置，中间的边的id，和两侧的两个面的id，这些都显然可得，所以就不加赘述。</p><p>可是两侧的同一个三角的两条腰只能保留其中一个，我们得决定保留哪一条。<br>我先画出了如下的示意图，所有点线面的id都是依据我实际时候的测试模型的值来，只是为了标记而已。顶点用红色$(vert_ {id})$表示，边用蓝色$[edge_ {id}]$表示，面用绿色$\{face_ {id}\}$表示<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/vertex_split_operator/2.1_before_collapse.png" alt title="原始结构id，有些部分如halfedge，为了避免干扰画面就省去了"><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/vertex_split_operator/2.2_collapsing.png" alt title="collapse的过程拆解示意图"><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/vertex_split_operator/2.3_after_collapsing.png" alt title="最终留下的结构"></p><p>之所以设计这样的坍缩方式，是因为我们可以在不影响除坍缩边及其相邻面的情况下完成连接性的重新构建。<br>先规定如下变量<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/vertex_split_operator/3.1_origin_struct.png" alt title="这里图示进行了放大和化简。所标注的是点线面结构，故不再使用括号，颜色也有调整"><br>由于坍缩之后，原始结构中，坍缩边的1-ring 平行的临边集合（图中id为{9,10,11,12,13,14}）都有一条指向坍缩后顶点的halfedge，并且我们保持坍缩过程不改变这个结构。所以我们可以利用这个来判断一条halfedge是否不属于要删除的腰。<br>我们首先遍历坍缩边的两个顶点v0,v1的所有相邻halfedge（放射状，且都是从坍缩边的顶点出发），并找出这条half-edge的next的终点，如果属于v0或v1，我们就知道这属于会被删去的腰中的一个<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Outward radial halfedges</span></span><br><span class="line"><span class="built_in">vector</span>&lt;HalfedgeIter&gt; adjHes = e-&gt;AdjHalfedges();</span><br><span class="line"><span class="comment">// Outward radial edges</span></span><br><span class="line"><span class="built_in">set</span>&lt;EdgeIter&gt; adjEs = e-&gt;AdjEdges();</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> adjHe : adjHes) &#123;</span><br><span class="line">    <span class="keyword">if</span> (find(adjEs.begin(), adjEs.end(), adjHe-&gt;next()-&gt;edge()) == adjEs.end())) &#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (adjHe-&gt;next()-&gt;twin()-&gt;vertex() == v0) &#123;</span><br><span class="line">            e0_del = adjHe-&gt;next()-&gt;edge()-&gt;id;</span><br><span class="line">            <span class="comment">// The existing one should be the edge of other end point</span></span><br><span class="line">            e1_cur = adjHe-&gt;edge()-&gt;id;</span><br><span class="line">            f0_del_id = adjHe-&gt;face()-&gt;id;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (adjHe-&gt;next()-&gt;twin()-&gt;vertex() == v1) &#123;</span><br><span class="line">            e1_del = adjHe-&gt;next()-&gt;edge()-&gt;id;</span><br><span class="line">            <span class="comment">// The existing one should be the edge of other end point</span></span><br><span class="line">            e0_cur = adjHe-&gt;edge()-&gt;id;</span><br><span class="line">            f1_del_id = adjHe-&gt;face()-&gt;id;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这样一来，所有我们删去的点线面的id信息都记录了下来，这将在后面重建时用到。</p><h1 id="开始split"><a href="#开始split" class="headerlink" title="开始split!"></a>开始split!</h1><p>首先根据之前记录的坍缩腰的id来找到对应的边和halfedge，并根据朝向，定义h0_in，h0_out，h1_in，h1_out.图示如下<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/vertex_split_operator/3.2_before_split_struct.png" alt title><br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">VertexCollapseRecord rec = v0-&gt;collapseRecords[<span class="number">0</span>];</span><br><span class="line">...</span><br><span class="line"><span class="built_in">vector</span>&lt;HalfedgeIter&gt; v0_adjHes = v0-&gt;AdjHalfedges();</span><br><span class="line">HalfedgeIter h0_in = (*(<span class="built_in">std</span>::find_if(v0_adjHes.begin(), v0_adjHes.end(),</span><br><span class="line">    [rec](<span class="keyword">const</span> HalfedgeIter&amp;h) &#123;<span class="keyword">return</span> h-&gt;edge()-&gt;id == rec.e0_cur_id; &#125;)))</span><br><span class="line">    -&gt;twin();</span><br><span class="line">HalfedgeIter h1_in = (*(<span class="built_in">std</span>::find_if(v0_adjHes.begin(), v0_adjHes.end(),</span><br><span class="line">    [rec](<span class="keyword">const</span> HalfedgeIter&amp;h) &#123;<span class="keyword">return</span> h-&gt;edge()-&gt;id == rec.e1_cur_id; &#125;)))</span><br><span class="line">    -&gt;twin();</span><br><span class="line">HalfedgeIter h0_out = h1_in-&gt;twin();</span><br><span class="line">HalfedgeIter h1_out = h0_in-&gt;twin();</span><br></pre></td></tr></table></figure></p><p>分离过程可以想象成，将两对half-edge剥开，然后在中间塞入两个三角形<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/vertex_split_operator/3.3_after_split_struct.png" alt title="淡绿色和虚线都表示新加的结构"><br>拉开halfedge之后，需要重新链接它们和相邻的halfedge，这一步要特别小心<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Setup inner halfedges' connectivity</span></span><br><span class="line">HalfedgeIter h_e0 = newHalfedge(), h_e0_n = newHalfedge(), h_e0_nn = newHalfedge();</span><br><span class="line">HalfedgeIter h_e1 = newHalfedge(), h_e1_n = newHalfedge(), h_e1_nn = newHalfedge();</span><br><span class="line">h_e0-&gt;setNeighbors(     h_e0_n,     h_e1,       v0,             e,              f0_del);</span><br><span class="line">h_e0_n-&gt;setNeighbors(   h_e0_nn,    h1_in,      v1,             h1_in-&gt;edge(),  f0_del);</span><br><span class="line">h_e0_nn-&gt;setNeighbors(  h_e0,       h0_out,     h1_in-&gt;vertex(),e0_del,         f0_del);</span><br><span class="line">h_e1-&gt;setNeighbors(     h_e1_n,     h_e0,       v1,             e,              f1_del);</span><br><span class="line">h_e1_n-&gt;setNeighbors(   h_e1_nn,    h0_in,      v0,             h0_in-&gt;edge(),  f1_del);</span><br><span class="line">h_e1_nn-&gt;setNeighbors(  h_e1,       h1_out,     h0_in-&gt;vertex(),e1_del,         f1_del);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Re-pair existing halfedges with newly created inner ones</span></span><br><span class="line">h0_out-&gt;edge() = e0_del;</span><br><span class="line">h1_out-&gt;edge() = e1_del;</span><br><span class="line">h0_in-&gt;twin() = h_e1_n;</span><br><span class="line">h0_out-&gt;twin() = h_e0_nn;</span><br><span class="line">h1_in-&gt;twin() = h_e0_n;</span><br><span class="line">h1_out-&gt;twin() = h_e1_nn;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Setup mesh elements</span></span><br><span class="line">v0-&gt;halfedge() = h_e0;</span><br><span class="line">v1-&gt;halfedge() = h_e1;</span><br><span class="line">e-&gt;halfedge() = h_e0;</span><br><span class="line">e0_del-&gt;halfedge() = h_e0_nn;</span><br><span class="line">e1_del-&gt;halfedge() = h_e1_nn;</span><br><span class="line">f0_del-&gt;halfedge() = h_e0;</span><br><span class="line">f1_del-&gt;halfedge() = h_e1;</span><br></pre></td></tr></table></figure></p><p>还有几个特别容易忘记更新的地方<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/vertex_split_operator/3.4_update_struct.png" alt title><br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// If h_e0_n-&gt;edge() has h0_out as its halfedge, it has trouble...</span></span><br><span class="line">h_e0_n-&gt;edge()-&gt;halfedge() = h_e0_n;</span><br><span class="line">h_e1_n-&gt;edge()-&gt;halfedge() = h_e1_n;</span><br><span class="line"></span><br><span class="line"><span class="comment">// For h1_in.next() and h1_out, they have v0 as their vertex. </span></span><br><span class="line"><span class="comment">// As we pinch them to the right, they should update their vertex to v1</span></span><br><span class="line"><span class="keyword">auto</span> v1hs = v1-&gt;AdjHalfedges();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> h : v1hs) &#123;</span><br><span class="line">    h-&gt;vertex() = v1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="collapse序列信息的存储"><a href="#collapse序列信息的存储" class="headerlink" title="collapse序列信息的存储"></a>collapse序列信息的存储</h1><p>对于class VertexCollapseRecord，我们可以定义如下的字段<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> v0_id, v1_id, e_id;</span><br><span class="line"><span class="keyword">int</span> e0_cur_id, e0_del_id, e1_cur_id, e1_del_id;</span><br><span class="line"><span class="keyword">int</span> f0_del_id, f1_del_id;</span><br><span class="line">Vector3D v1_pos; <span class="comment">// position of the other removed vertex</span></span><br><span class="line">Vector3D v0_pos; <span class="comment">// Last position of this vertex</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">bool</span> isValid = <span class="literal">false</span>;</span><br><span class="line"><span class="keyword">int</span> nextRecOffset = <span class="number">1</span>;</span><br></pre></td></tr></table></figure></p><p>其中上半部分比较好理解，即我们上面所说的各种id和坐标，用来还原结构的。而下半部分则是用来帮助我们完成坍缩序列记录的，即我们希望坍缩的还原是能够完全按照之前的顺序进行的。</p><p>假设坍缩记录会记录两个端点各自的坍缩序列，那么我们势必涉及到要将各自的坍缩记录嵌套起来才能存储。没有什么简单的方法能支持这种嵌套的数据类型，所以我干脆用数组的方式进行嵌套的模拟。思路倒是和用数组的跳转表来表示稀疏邻接矩阵有些相似。<br>合并的图示如下<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/vertex_split_operator/4.1_vertex_merge.png" alt title></p><p>id数组的构成如下<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/vertex_split_operator/4.2_vertex_id_array.png" alt title><br>这样我们就可以将“嵌套”的顶点id列表存在一个flat的数组中，也不用管理恼人的指针了。每次在split一个顶点的时候，只用先找到active vert或者merged vert的头，读取到它的长度，就可以知道当前顶点的坍缩历史。在创建新顶点完成之后，将这块坍缩历史再更新到新的顶点就好。数据顺序都不会被破坏。</p><p>坍缩边时构建id array<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Generate collapse info record ////////////////////////</span></span><br><span class="line"><span class="keyword">if</span> (v0_colRecs.size() == <span class="number">0</span>) &#123;</span><br><span class="line">    v0_colRecs.push_back(VertexCollapseRecord());</span><br><span class="line">    v0_colRecs[<span class="number">0</span>].v0_id = v0_id;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (v1_colRecs.size() == <span class="number">0</span>) &#123;</span><br><span class="line">    v1_colRecs.push_back(VertexCollapseRecord());</span><br><span class="line">    v1_colRecs[<span class="number">0</span>].v0_id = v1_id;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> nextOffset = <span class="number">1</span>; <span class="comment">// First point to the start of v0 collapseRecords</span></span><br><span class="line">nextOffset += v0_colRecs[<span class="number">0</span>].nextRecOffset; <span class="comment">// Next point to the start of v1 collapseRecords</span></span><br><span class="line">nextOffset += v1_colRecs[<span class="number">0</span>].nextRecOffset; <span class="comment">// Finally point to the end/the start of next collapseRecords subtree</span></span><br><span class="line">VertexCollapseRecord rec = VertexCollapseRecord(eid, v0_id, v1_id, v0_pos, v1_pos,</span><br><span class="line">    e0_cur, e0_del, e1_cur, e1_del, f0_del_id, f1_del_id, nextOffset);</span><br><span class="line">newV-&gt;collapseRecords.push_back(rec);</span><br><span class="line">newV-&gt;collapseRecords.insert(newV-&gt;collapseRecords.end(), v0_colRecs.begin(), v0_colRecs.end());</span><br><span class="line">newV-&gt;collapseRecords.insert(newV-&gt;collapseRecords.end(), v1_colRecs.begin(), v1_colRecs.end());</span><br></pre></td></tr></table></figure></p><p>在split的时候，把两个部分再解出来。这里我还用了一个isValid来代表这是否是叶子节点，如果是叶子节点，代表这个顶点从没有被合并过，是原始顶点，所以不能split<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">VertexCollapseRecord rec = v0-&gt;collapseRecords[<span class="number">0</span>];</span><br><span class="line">VertexCollapseRecord v0_prev_rec = v0-&gt;collapseRecords[<span class="number">1</span>];</span><br><span class="line">VertexCollapseRecord v1_prev_rec = v0-&gt;collapseRecords[<span class="number">1</span> + v0_prev_rec.nextRecOffset];</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (rec.isValid == <span class="literal">false</span>) &#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"Selected vertex doesn't have any collapse info"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> edges.end();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">v0-&gt;collapseRecords.assign(</span><br><span class="line">    v0-&gt;collapseRecords.begin() + <span class="number">1</span>, </span><br><span class="line">    v0-&gt;collapseRecords.begin() + <span class="number">1</span> + v0_prev_rec.nextRecOffset);</span><br><span class="line">v1-&gt;collapseRecords.assign(</span><br><span class="line">    v0-&gt;collapseRecords.begin() + <span class="number">1</span> + v0_prev_rec.nextRecOffset, </span><br><span class="line">    v0-&gt;collapseRecords.end());</span><br></pre></td></tr></table></figure></p><h1 id="找寻合适的插入点"><a href="#找寻合适的插入点" class="headerlink" title="找寻合适的插入点"></a>找寻合适的插入点</h1><p>有些情况下，我们并不一定要准确的还原merge的顶点的原始位置。例如，我们对模型球面参数化之后，我们希望还原的顶点落在球面上，只是保持原来的相对拓扑关系，并不要求位置一致。于是我们就需要根据其周围顶点的位置，判断哪里是合适的插入位置<br>首先，我们把3D问题划归到2D平面上。我们假设球面参数化之后，所有顶点都分布潜在球面上且没有交叠的部分，于是我们就可以近似的将相邻点构成的面看出一个微分平面，而这个法线则是这个多边形中每个小三角形的有向面积<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Get adjective vertices plane's normal</span></span><br><span class="line"><span class="function">Vector3D <span class="title">N</span><span class="params">(<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>)</span></span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; v1_ajdVs.size(); ++i) &#123;</span><br><span class="line">    Vector3D vec_pi = v1_ajdVs[i]-&gt;position;</span><br><span class="line">    Vector3D vec_pj = v1_ajdVs[(i + <span class="number">1</span>) % v1_ajdVs.size()]-&gt;position;</span><br><span class="line">    N += cross(vec_pi, vec_pj);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (N.norm() &gt; <span class="number">1e-5</span>)</span><br><span class="line">    N = N.unit();</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    N = Vector3D(<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>);</span><br></pre></td></tr></table></figure></p><p>通过$point - dot(point, N) * N)$可以将一个点投影到这个微平面上。</p><p>B.Mocanu<a href="#ref">[2]</a>提出的检测合法点需要将平面分割成很多个小点再对所有点进行可见性测试，即如果从新的顶点与之前的顶点相连的边和旧的边有相交即为非法<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/vertex_split_operator/5.1_bm_valid_check.png" alt title><br>下面给出了几个合法和非法的例子<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/vertex_split_operator/5.2_before_split.png" alt title><br>这个例子中，主要的问题在于向内凹角的两侧的顶点不容易被新的顶点“看到”，如果我们用半平面交画出范围，可以看到只有中间的重叠颜色才是合法的区域<br>首先是一个合法的位置<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/vertex_split_operator/5.3_valid_pos.png" alt title><br>接着是一个非法的位置，这里三角形v1-v0-v6已经flip了，所以是个非法的面<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/vertex_split_operator/5.4_invalid_pos.png" alt title></p><p><span id="ref"></span></p><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><p><a href="http://hhoppe.com/pm.pdf" target="_blank" rel="noopener">[1] Progressive Meshes [Hugues Hoppe. ACM SIGGRAPH 1996 Proceedings, 99-108]</a><br><a href>[2] Direct spherical parameterization based on surface curvature [B. Mocanu, T. Zaharia]</a></p>]]></content>
      
      
      <categories>
          
          <category> Algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graphics </tag>
            
            <tag> geometry </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于高斯曲率的mesh扁平化</title>
      <link href="/2020/03/07/curvature_driven_flattening/"/>
      <url>/2020/03/07/curvature_driven_flattening/</url>
      
        <content type="html"><![CDATA[ <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/curvature_driven_flattening/0_curvature_flattening_cover.png" alt title><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>在Geometry Processing中，我们有时候需要对一个mesh进行参数化。对于一个开放的含边界的mesh，我们一般会采用planar parameterization。可以想象将一层附于物体表面的“皮”摊平在一个2D泡面。但对于一个genus-0的封闭mesh，直接展平不可避免的会出现许多的畸变和扭曲。所以我们考虑将其参数化到同胚的单位球上。<br>一般来说，复杂的多面体无法通过stereographic projection（球极平面投影）直接投射到单位球上。换个角度理解，即无法从几何体的几何中心无遮挡的看到三角面上的所有顶点。三角面在单位球上的投影会overlap或者flip。这都会导致参数化的失败。一般问题的发生场所都是在mesh的突出部分，所以在本文中，将会利用curvature-driven faltenning技术完成对mesh不改变拓扑的扁平化。从而能更好的进行参数化。<br><a id="more"></a></p><h1 id="曲率"><a href="#曲率" class="headerlink" title="曲率"></a>曲率</h1><p>曲率本身是一个二阶连续的表面的二阶导数。但是对于3D模型来说，它是离散的且只有$C^0$连续。所以我们需要对其进行一个分段的线性近似。</p><h2 id="Gaussian曲率的定义"><a href="#Gaussian曲率的定义" class="headerlink" title="Gaussian曲率的定义"></a>Gaussian曲率的定义</h2> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/curvature_driven_flattening/1_definition.png" alt title><p>如果我们定义$p_i, p, p_{i+1}$构成的夹角为$\alpha$，那么点p处的angular defect就为<br>$$\delta =2\pi -\sum _{i} \alpha _{i}$$<br>然后高斯曲率K为<br>\[K=\frac{2\pi -\sum\limits _{i} \alpha _{i}}{G}\]<br>其中G为几何项，上图中的蓝色部分<br>\[G=\sum\limits _{i} A _{i}( p) /3\]<br>最后化简为<br>\[<br>K=\frac{3\left( 2\pi -\sum\limits _{i} \alpha _{i}\right)}{\sum\limits _{i} A _{i}( p)}<br>\]<br>其中$A _{i}(p)$是领接与点p的三角形$Tri_i$的面积</p><h1 id="算法思路"><a href="#算法思路" class="headerlink" title="算法思路"></a>算法思路</h1><p>首先计算出在mesh上的每个顶点的高斯曲率$K_p$。然后我们挑出曲率最大的一个顶点$p_{max}$，即我们看到的最突出的地方。我们计算能让它的曲率变小的目标位置$p’_{max}$<br>\[<br>p’ _ {max}=\frac{\sum _ {p_{i} \in Neigh( p_{max})} p_{i}}{val( p_ {max})}<br>\]<br>其中$Neigh( p_{max})$代表$p_{max}$的所有相邻点。$val( p_ {max})$是点$p_{max}$的度。上面的式子其实就代表了相邻顶点的几何中心（或者说算术平均位置）<br>如果$p_{max}$的目标位置和$p_{max}$的原始位置的距离超过了阈值$dist$，俺么我们就移动$p_{max}$到$p’ _{max}$。否则，我们就跳过$p _{max}$，继续找下一个曲率最大的点，尝试更新位置。该操作一直会持续到找到一个点位置。<br>当成功更新了一个顶点的位置之后，我们就会更新相应的高斯曲率并开始下一次迭代。</p><p>值得一提的是，离散高斯曲率的计算有不同形式，但是这种表示方式是一种local的表示，也即意味着如果一个顶点的位置发生了改版，那我们只用更新它相关的顶点并重新计算即可，具有locality。</p><p>不断重复上述的过程，最终的效果是将mesh中突出的部分渐渐打磨成圆角。理想的最终结果是一个接近于球的形状。<br>不过上面式子中的$K_p$在遇到某个小区域内有大量顶点的时候（通常是模型表现细节的地方），由于每个三角形的面积趋向于0，所以会对迭代算法造成不利的影响，收敛速度会大大减慢。为了解决这个问题，于是Mocanu<a href="#ref">[3]</a>提出了一个系数$\chi _{s}$<br>\[<br>\chi _ {s} =\frac{\sum\limits _ {i} A( Tri_{i})}{n_{Tri}}<br>\]<br>这个$\chi _{s}$代表了整个mesh的所有三角面的平均大小。这个纠正因子可以通过加强angular defect的影响而改善迭代的效果。最终修改过的高斯曲率$K_s$为<br>\[<br>K_{s} =\frac{2\pi -\sum\limits _ {i} \alpha _ {i}}{\chi _ {s} +\sum\limits _ {i} A_ {i}( p) /3}<br>\]</p><p>这个步骤会不断进行。在结束的时候，会用一些PCA和大小归一化的方法来避免产生萎缩的问题</p><h1 id="算法实现细节"><a href="#算法实现细节" class="headerlink" title="算法实现细节"></a>算法实现细节</h1><h2 id="Step1"><a href="#Step1" class="headerlink" title="Step1"></a>Step1</h2><p>首先先对mesh的全部三角面计算一次平均面积。在此过程中，三角形的面积会cache，这样后面只需更新那些移动顶点位置了的三角的cahcedArea就可以进行进一步迭代了。体现了local操作的性能优势<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> average_face_area = <span class="number">0.0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> f = mesh.facesBegin(); f != mesh.facesEnd(); f++) &#123;</span><br><span class="line">    f-&gt;cachedArea = f-&gt;area();</span><br><span class="line">    average_face_area += f-&gt;cachedArea;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Get Xs</span></span><br><span class="line">average_face_area /= mesh.nFaces();</span><br></pre></td></tr></table></figure></p><h2 id="Step2"><a href="#Step2" class="headerlink" title="Step2"></a>Step2</h2><p>接着对每个顶点生成一个曲率的记录，主要记录当前曲率和曲率减小的目标点的位置。计算时会需要用到刚才的平均面积<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">MutablePriorityQueue&lt;VertexRecord&gt; <span class="built_in">queue</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> v = mesh.verticesBegin(); v != mesh.verticesEnd(); v++) &#123;</span><br><span class="line">    v-&gt;record = VertexRecord(v, average_face_area);</span><br><span class="line">    <span class="built_in">queue</span>.insert(v-&gt;record);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="Step3"><a href="#Step3" class="headerlink" title="Step3"></a>Step3</h2><p>不断的找出最大曲率的点并尝试更新。<br>对于那些虽然曲率很大，但是移动距离没有能达到阈值要求的顶点，我们会暂时将他们的曲率设为0，并重新插入优先队列。这样他们就不会在本次迭代中再次被访问和判断。只有在已经成功选出一个更新点并更新位置之后，它们的曲率才会再次得到计算和更新。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="built_in">queue</span>.top().offset &lt; threshold) &#123;</span><br><span class="line">    VertexRecord maxCurvedV = <span class="built_in">queue</span>.top();</span><br><span class="line">    <span class="built_in">queue</span>.pop();</span><br><span class="line">    <span class="comment">// Make vR the least "curved" vert and insert back to queue.</span></span><br><span class="line">    maxCurvedV.curvature = <span class="number">0.0</span>;</span><br><span class="line">    <span class="built_in">queue</span>.insert(maxCurvedV);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="Step4"><a href="#Step4" class="headerlink" title="Step4"></a>Step4</h2><p>对于满足条件，需要更新的顶点。在完成位置移动之后，我们首先要更新它相邻三角面的面积。同时注意，此时mesh的平均面积也发生了变化，可是我们可以通过increment变量来局部的更新平均面积而不用整个再重新计算一遍。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Move p to pMax</span></span><br><span class="line">maxCurvedV.vert-&gt;position = maxCurvedV.optimalPoint;</span><br><span class="line"><span class="comment">// Update neighbor faces</span></span><br><span class="line"><span class="keyword">auto</span> adjFs = maxCurvedV.vert-&gt;AdjFaces();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> adjF : adjFs) &#123;</span><br><span class="line">    <span class="keyword">float</span> newArea = adjF-&gt;area();</span><br><span class="line">    <span class="comment">// Update Xs</span></span><br><span class="line">    average_face_area += (newArea - adjF-&gt;cachedArea) / mesh.nFaces();</span><br><span class="line">    <span class="comment">// Update face area before we use it to calculate our latest curvature</span></span><br><span class="line">    adjF-&gt;cachedArea = adjF-&gt;area();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="Step5"><a href="#Step5" class="headerlink" title="Step5"></a>Step5</h2><p>最后，别忘了将刚才更新过的顶点remove并re-insert回去，以便下一次能找到曲率最大的顶点。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Update current vert's curvature</span></span><br><span class="line">maxCurvedV.Update(average_face_area);</span><br><span class="line"></span><br><span class="line"><span class="comment">// As well as those neighbor verts</span></span><br><span class="line"><span class="keyword">auto</span> adjVerts = maxCurvedV.vert-&gt;AdjVertices();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> adjV : adjVerts) &#123;</span><br><span class="line">    <span class="built_in">queue</span>.remove(adjV-&gt;record);</span><br><span class="line">    adjV-&gt;record.Update(average_face_area);</span><br><span class="line">    <span class="built_in">queue</span>.insert(adjV-&gt;record);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// after updated maxCurvedV get re-insert to the queue to get the right order</span></span><br><span class="line"><span class="built_in">queue</span>.insert(maxCurvedV);</span><br></pre></td></tr></table></figure></p> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/curvature_driven_flattening/2_different_angle.png" alt title="此为近进行少量扁平化操作的结果，橙色处为扁平化明显的区域，可以看到相比家与原模型棱角处已经平滑了许多"> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/curvature_driven_flattening/3_sphere_like.png" alt title="这是扁平化操作较多的结果，更接近于球体。注：该过程中使用了多次downsampling，故顶点数看上去比较少"><p><span id="ref"></span></p><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><p><a href="http://http.cs.berkeley.edu/~jrs/meshpapers/MeyerDesbrunSchroderBarr.pdf" target="_blank" rel="noopener">[1] Discrete Differential-Geometry Operators for Triangulated 2-Manifolds [Meyer et al. 2003]</a><br><a href="http://rodolphe-vaillant.fr/?e=20" target="_blank" rel="noopener">[2] Compute Harmonic weights on a triangular mesh</a><br><a href="https://www.researchgate.net/publication/220844937_Direct_Spherical_Parameterization_of_3D_Triangular_Meshes_Using_Local_Flattening_Operations" target="_blank" rel="noopener">[3] Direct Spherical Parameterization of 3D Triangular Meshes Using Local Flattening Operations</a></p>]]></content>
      
      
      <categories>
          
          <category> Algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graphics </tag>
            
            <tag> geometry </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Quadric Error Metrics进行mesh简化</title>
      <link href="/2020/03/07/mesh_quadric_downsampling/"/>
      <url>/2020/03/07/mesh_quadric_downsampling/</url>
      
        <content type="html"><![CDATA[ <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/mesh_quadric_downsampling/0_downsampling_cover.png" alt title><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Hoppe等人在1993年的时候首先提出了一系列的mesh optimization技术<a href="#ref">[6]</a>，其中包括edge collapse, edge split, edge swap等操作。基于edge的操作相比较于之前的模型简化（或者说down-sampling）技术，如triangel collapse，最大的好处是能保证模型原始的拓扑结构，因此可以进一步用于其他的geometry processing操作。<br>关于模型化简时选择最合适的边进行collapse，我们需要选择那些坍缩后的边对原有的模型影响最小的边。Hoppe在论文中，使用的是能量方程来判断。但实际情况中，计算的成本过高。因此，在1997年的时候，Garland和Heckbert等人提出了一种基于Quaderic Error的度量标准<a href="#ref">[5]</a>来判断最合适的顶点。<br><a id="more"></a></p><h1 id="理论推导"><a href="#理论推导" class="headerlink" title="理论推导"></a>理论推导</h1><h2 id="点距平面的误差距离"><a href="#点距平面的误差距离" class="headerlink" title="点距平面的误差距离"></a>点距平面的误差距离</h2><p>我们用一个顶点到它的1-ring相邻面的距离之和来表示它的误差。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/mesh_quadric_downsampling/1_vertex_quadric_error.png" alt title="图中顶点v的error为v到平面P1,P2,P3的距离S1,S2,S3之和.来源[7]"></p><p>点v到平面上一点p的距离如图所示<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/mesh_quadric_downsampling/2_plane_dist.png" alt title><br>我们采用齐次坐标系下的向量形式表示顶点v<br>$$<br>v=\begin{bmatrix}<br>v_{x}\\<br>v_{y}\\<br>v_{z}\\<br>1<br>\end{bmatrix}<br>$$<br>同时，平面表达式$ax+by+cy+d=0$写成矩阵形式就是<br>$$<br> \begin{array}{l}<br>\begin{bmatrix}<br>a &amp; b &amp; c &amp; d<br>\end{bmatrix}\begin{bmatrix}<br>p_{x}\\<br>p_{y}\\<br>p_{z}\\<br>1<br>\end{bmatrix} =0\\<br>\Longrightarrow \begin{bmatrix}<br>a &amp; b &amp; c &amp; 0<br>\end{bmatrix}\begin{bmatrix}<br>p_{x}\\<br>p_{y}\\<br>p_{z}\\<br>1<br>\end{bmatrix} =-d<br>\end{array}<br>$$<br>前面提到的距离表达式可以写成<br>    $dist( v) \ =\ dot( N,\ v-p) =dot( N,v) -dot( N,p)$<br>平面法线由于是方向向量，故在齐次坐标系下w分量为0：$\begin{bmatrix}a &amp; b &amp; c &amp; 0\end{bmatrix}^{T}$<br>由前面的几个式子，从而可以进一步化简$dist(v)$<br>$$<br> \begin{array}{l}<br>=\begin{bmatrix}<br>a &amp; b &amp; c &amp; 0<br>\end{bmatrix}\begin{bmatrix}<br>v_{x}\\<br>v_{y}\\<br>v_{z}\\<br>1<br>\end{bmatrix} -\begin{bmatrix}<br>a &amp; b &amp; c &amp; 0<br>\end{bmatrix}\begin{bmatrix}<br>p_{x}\\<br>p_{y}\\<br>p_{z}\\<br>1<br>\end{bmatrix}\\<br>=\begin{bmatrix}<br>a &amp; b &amp; c &amp; 0<br>\end{bmatrix}\begin{bmatrix}<br>v_{x}\\<br>v_{y}\\<br>v_{z}\\<br>1<br>\end{bmatrix} +d\\<br>=\begin{bmatrix}<br>a &amp; b &amp; c &amp; d<br>\end{bmatrix}\begin{bmatrix}<br>v_{x}\\<br>v_{y}\\<br>v_{z}\\<br>1<br>\end{bmatrix}\\<br>\Longleftrightarrow \begin{bmatrix}<br>v_{x} &amp; v_{y} &amp; v_{z} &amp; 1<br>\end{bmatrix}\begin{bmatrix}<br>a\\<br>b\\<br>c\\<br>d<br>\end{bmatrix}<br>\end{array}<br>$$<br>$dist(v)$可正可负，我们只关注绝对值，所以我们对它求平方<br>$$<br>dist( v)^{2} =\left(\begin{bmatrix}<br>v_{x} &amp; v_{y} &amp; v_{z} &amp; 1<br>\end{bmatrix}\begin{bmatrix}<br>a\\<br>b\\<br>c\\<br>d<br>\end{bmatrix}\right) .\left(\begin{bmatrix}<br>a &amp; b &amp; c &amp; d<br>\end{bmatrix}\begin{bmatrix}<br>v_{x}\\<br>v_{y}\\<br>v_{z}\\<br>1<br>\end{bmatrix}\right)<br>$$<br>利用矩阵的结合律，$dist( v)^{2}$ 可以进一步表示为<br>$$<br>=v^{T}\begin{bmatrix}<br>a\\<br>b\\<br>c\\<br>d<br>\end{bmatrix}\begin{bmatrix}<br>a &amp; b &amp; c &amp; d<br>\end{bmatrix} v<br>$$<br>令<br>$$<br>Q_p=\begin{bmatrix}<br>a\\<br>b\\<br>c\\<br>d<br>\end{bmatrix}\begin{bmatrix}<br>a &amp; b &amp; c &amp; d<br>\end{bmatrix}<br>$$<br>这是一个只和平面相关的参数，可以表示任意一点到该平面的距离系数。我们这里将其称为点v到平面P的误差矩阵<br>$$<br>Q_{p}=\begin{bmatrix}<br>q_{11} &amp; q_{12} &amp; q_{13} &amp; q_{14}\\<br>q_{21} &amp; q_{22} &amp; q_{23} &amp; q_{24}\\<br>q_{31} &amp; q_{32} &amp; q_{33} &amp; q_{34}\\<br>q_{41} &amp; q_{42} &amp; q_{43} &amp; q_{44}<br>\end{bmatrix} \Longleftrightarrow \begin{bmatrix}<br>a^{2} &amp; ab &amp; ac &amp; ad\\<br>ab &amp; b^{2} &amp; bc &amp; bd\\<br>ac &amp; bc &amp; c^{2} &amp; cd\\<br>ad &amp; bd &amp; cd &amp; d^{2}<br>\end{bmatrix}<br>$$</p><h2 id="边坍缩的误差代价"><a href="#边坍缩的误差代价" class="headerlink" title="边坍缩的误差代价"></a>边坍缩的误差代价</h2><p>对于edge collapse(contract)操作$$( v_{1} ,\ v_{2}) \ \rightarrow \ v’$$<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/mesh_quadric_downsampling/3_edge_contraction_operator.png" alt title="v1,v2坍缩到v，由于v是新创建的，所以更准确的说这属于full-edge collapse"><br>假设对于某一坍缩边$(v1, v2)$，其收缩后顶点变为 $v’$，我们定义顶点 $v’$ 的误差矩阵为两个合并前的顶点误差矩阵的和：$Q_1+Q_2$，并且可以得到误差代价$\Delta (v’)$<br>$$\Delta (v’)=v’^{T}( Q_{1} +Q_{2})v’=v’^{T} Q_{e}v’$$<br>如果我们希望坍缩操作对模型本身的影响最小，那么就是希望 $\Delta (v’)$ 取到最小值。</p><p>通过将前面的误差矩阵的矩阵形式替换$\Delta (v’)$，我们可以得到<br>$$<br>\Delta (v’)=v’^{T}\begin{bmatrix}<br>q_{11} &amp; q_{12} &amp; q_{13} &amp; q_{14}\\<br>q_{21} &amp; q_{22} &amp; q_{23} &amp; q_{24}\\<br>q_{31} &amp; q_{32} &amp; q_{33} &amp; q_{34}\\<br>q_{41} &amp; q_{42} &amp; q_{43} &amp; q_{44}<br>\end{bmatrix}v’<br>$$<br>$\Delta (v’)$写成向量$v’( x,\ y,\ z)$并用齐次坐标形式做矩阵乘法化简后可得到<br>$$<br> \begin{array}{l}<br>\Delta (v’)=\begin{bmatrix}<br>x &amp; y &amp; z &amp; 1<br>\end{bmatrix}\begin{bmatrix}<br>q_{11} &amp; q_{12} &amp; q_{13} &amp; q_{14}\\<br>q_{21} &amp; q_{22} &amp; q_{23} &amp; q_{24}\\<br>q_{31} &amp; q_{32} &amp; q_{33} &amp; q_{34}\\<br>q_{41} &amp; q_{42} &amp; q_{43} &amp; q_{44}<br>\end{bmatrix}\begin{bmatrix}<br>x\\<br>y\\<br>z\\<br>1<br>\end{bmatrix}\\<br>=\begin{bmatrix}<br>q_{11} x+q_{21} y+q_{31} z+q_{41} &amp; q_{12} x+q_{22} y+q_{32} z+q_{42} &amp; q_{13} x+q_{23} y+q_{33} z+q_{43} &amp; q_{14} +q_{24} +q_{34} +q_{44}<br>\end{bmatrix}\begin{bmatrix}<br>x\\<br>y\\<br>z\\<br>1<br>\end{bmatrix}\\<br>=\left( q_{11} x^{2} +q_{21} xy+q_{31} xz+q_{41} x\right) +\left( q_{12} xy+q_{22} y^{2} +q_{32} yz+q_{42} y\right)\\<br>\ \ \ \ +\left( q_{13} xz+q_{23} yz+q_{33} z^{2} +q_{43} z\right) +(q_{14} x+q_{24} y+q_{34} z+q_{44} )\\<br>=\left( q_{11} x^{2} +q_{22} y^{2} +q_{33} z^{2}\right) +2(q_{14} x+q_{24} y+q_{34} z)+2(q_{12} xy+q_{13} xz+q_{23} yz)+q_{44}<br>\end{array}<br>$$<br>上面的计算过程的最后一步其实是有一个隐式的替换。同时因为误差矩阵Q是一个对称矩阵，所以$q_{ij}=q_{ji}$(例如 $q_{14}=q_{41}$)，所以可以合并同类项。<br>幸运的是，由于$\Delta (v’)$的表达式最终是一个二次项形式，我们可以通过找到一个 $\Delta (v’)’$为0的值来找出它的最小值。即令它对x,y,z的一阶偏导都为0<br>$$\frac{\partial \Delta (v’)}{\partial x} =\frac{\partial \Delta (v’)}{\partial y} =\frac{\partial \Delta (v’)}{\partial z} =0$$<br>这里演示$\frac{\partial \Delta (v’)}{\partial x}$的推导<br>$$<br> \begin{array}{l}<br>\frac{\partial \Delta (v’)}{\partial x} =2q_{11} x+2q_{12} y+2q_{13} z+2q_{14}\\<br>=2\begin{bmatrix}<br>q_{11} &amp; q_{12} &amp; q_{13} &amp; q_{14}<br>\end{bmatrix}\begin{bmatrix}<br>x\\<br>y\\<br>z\\<br>1<br>\end{bmatrix}\\<br>\therefore \begin{bmatrix}<br>q_{11} &amp; q_{12} &amp; q_{13} &amp; q_{14}<br>\end{bmatrix} \ v’=0<br>\end{array}<br>$$<br>同理可以应用于对y,z的偏微分。故可得<br>$$<br>\begin{bmatrix}<br>q_{11} &amp; q_{12} &amp; q_{13} &amp; q_{14}\\<br>q_{21} &amp; q_{22} &amp; q_{23} &amp; q_{24}\\<br>q_{31} &amp; q_{32} &amp; q_{33} &amp; q_{34}\\<br>0 &amp; 0 &amp; 0 &amp; 1<br>\end{bmatrix}\begin{bmatrix}<br>x\\<br>y\\<br>z\\<br>1<br>\end{bmatrix} =\begin{bmatrix}<br>0\\<br>0\\<br>0\\<br>1<br>\end{bmatrix}<br>$$<br>因为最下面一行不用处理，将左边的4x4矩阵还可以拆成一个3x3矩阵和3x1矩阵分别乘以 $v’$ 所以式子还可以写成<br>$$<br> \begin{array}{l}<br>\begin{bmatrix}<br>q_{11} &amp; q_{12} &amp; q_{13}\\<br>q_{21} &amp; q_{22} &amp; q_{23}\\<br>q_{31} &amp; q_{32} &amp; q_{33}<br>\end{bmatrix}\begin{bmatrix}<br>x\\<br>y\\<br>z<br>\end{bmatrix} +\begin{bmatrix}<br>q_{14}\\<br>q_{24}\\<br>q_{34}<br>\end{bmatrix}\begin{bmatrix}<br>1\\<br>1\\<br>1<br>\end{bmatrix} =\begin{bmatrix}<br>0\\<br>0\\<br>0<br>\end{bmatrix}\\<br>\begin{bmatrix}<br>q_{11} &amp; q_{12} &amp; q_{13}\\<br>q_{21} &amp; q_{22} &amp; q_{23}\\<br>q_{31} &amp; q_{32} &amp; q_{33}<br>\end{bmatrix}\begin{bmatrix}<br>x\\<br>y\\<br>z<br>\end{bmatrix} =-\begin{bmatrix}<br>q_{14}\\<br>q_{24}\\<br>q_{34}<br>\end{bmatrix}\\<br>\\<br>v’=\begin{bmatrix}<br>q_{11} &amp; q_{12} &amp; q_{13}\\<br>q_{21} &amp; q_{22} &amp; q_{23}\\<br>q_{31} &amp; q_{32} &amp; q_{33}<br>\end{bmatrix}^{-1}\begin{bmatrix}<br>-q_{14}\\<br>-q_{24}\\<br>-q_{34}<br>\end{bmatrix}<br>\end{array}<br>$$</p><p>由前面推导的，用平面方程表示的误差矩阵$Q_p$，我们可以得到<br>$$<br>v’=\begin{bmatrix}<br>a^{2} &amp; ab &amp; ac\\<br>ab &amp; b^{2} &amp; bc\\<br>ac &amp; bc &amp; c^{2}<br>\end{bmatrix}^{-1}\begin{bmatrix}<br>-ad\\<br>-bd\\<br>-cd<br>\end{bmatrix}<br>$$<br>这个$v’$也即理论上我们想要找的边坍缩后，最优点的位置。不过这个理论的位置不一定一直存在。例如系数逆矩阵如果不存在逆矩阵，就无法求解。这个时候我们就只能使用备选方案，<br>在$v_{1} ,\ v_{2}$ 和$( v_{1} +\ v_{2}) /2$三个位置中选择一个最合适的点的位置进行坍缩。<br>有了最优点，再代回<br>$$\Delta (v’)=v’^{T}( Q_{1} +Q_{2})v’=v’^{T} Q_{e}v’$$<br>我们就可以知道某一条边的坍缩代价</p><h2 id="坍缩策略"><a href="#坍缩策略" class="headerlink" title="坍缩策略"></a>坍缩策略</h2><p>知道了每条边的坍缩代价之后，我们要想尽可能的保留模型原始形状的同时简化边，只要采用贪心的策略不断删去坍缩代价最小的边即可。虽然这个坍缩操作是local operation，不过仍需记得更新相应的相邻点，边，面的坍缩代价。</p><h1 id="算法实现细节"><a href="#算法实现细节" class="headerlink" title="算法实现细节"></a>算法实现细节</h1><p>基本步骤：<br>1.首先遍历mesh上所有面，对每一个面计算它的误差矩阵（这与顶点位置无关，所以可以先求）即<br>$$<br>Q_p=\begin{bmatrix}<br>a\\<br>b\\<br>c\\<br>d<br>\end{bmatrix}\begin{bmatrix}<br>a &amp; b &amp; c &amp; d<br>\end{bmatrix}<br>$$<br>平面法线$\vec{n}( a,\ b,\ c)$可以由平面法线f-&gt;normal()得到。平面的表达式中的d，可以将平面上任意一个顶点的坐标代入平面表达式$ax+by+cy+d=0$中解得。最后在算Q的时候，也不必逐项相乘，如果可以直接使用外积函数自然最为方便<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f-&gt;quadric = outer(Vector4D(n, d), Vector4D(n, d));</span><br></pre></td></tr></table></figure></p><p>2.遍历mesh上所有顶点，对每一个顶点计算它的1-ring相邻面的误差矩阵，直接累加即可。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (VertexIter v = mesh.verticesBegin(); v != mesh.verticesEnd(); ++v) &#123;</span><br><span class="line">    v-&gt;quadric.zero();</span><br><span class="line">    HalfedgeCIter h = v-&gt;halfedge();    <span class="comment">// get one of the outgoing halfedges of the vertex</span></span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        FaceCIter f = h-&gt;face();</span><br><span class="line">        <span class="comment">// Add up all quadric of vert's 1-ring faces</span></span><br><span class="line">        v-&gt;quadric += f-&gt;quadric;</span><br><span class="line"></span><br><span class="line">        h = h-&gt;twin()-&gt;next();          <span class="comment">// move to the next outgoing halfedge of the vertex.</span></span><br><span class="line">    &#125; <span class="keyword">while</span> (h != v-&gt;halfedge());       <span class="comment">// keep going until we're back at the beginning</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>3.遍历mesh上所有边，对于每条边，将它的两个端点的误差矩阵和作为边的误差矩阵。然后计算它的最优坍缩点及其代价。<br>由于我们的坍缩操作是贪心的，每次只取坍缩代价最小的那条边。每次坍缩完成后，因为更新了顶点的位置和周围的1-ring点关联。所以我们会局部的更新相邻的所有涉及到变化的顶点的误差矩阵，再相应的更新面和边的误差矩阵，以便我们下一次迭代能得到最新的坍缩代价。这里推荐使用优先队列来存储每条边的坍缩记录，这样将复杂度降为O(log(N))。而使用一个额外的CollapseRecord结构的原因有两个：1.可以事先将最优点和代价存储在记录中，并持有边的引用。这样优先队列在排序的时候会减少存储空间。2.记录下坍缩的原始顶点可以帮助后面可能进行的还原操作。<br>这里坍缩的过程也需要小心。在处理每一条需要坍缩的边的时候，要先将其两个端点相关的1-ring领边的坍缩记录从队列中删去（因为后面需要更新），再进行坍缩。坍缩完成之后更新新顶点的1-ring相邻面。以及更新新的顶点的quadric误差矩阵。最后将新的坍缩记录插回优先队列完成更新。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Insert any edge touching the new vertex into the queue, creating new edge records for each of them.</span></span><br><span class="line">h = newV-&gt;halfedge();</span><br><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line">    h-&gt;edge()-&gt;record = CollapseRecord(h-&gt;edge());</span><br><span class="line">    <span class="built_in">queue</span>.insert(h-&gt;edge()-&gt;record);</span><br><span class="line"></span><br><span class="line">    h = h-&gt;twin()-&gt;next();</span><br><span class="line">&#125; <span class="keyword">while</span> (h != newV-&gt;halfedge());</span><br></pre></td></tr></table></figure></p><p>这样才算是完成了一次坍缩。这个过程可能需要多次进行才能将mesh化简实现down sampling，也可以设定一个目标的边的数量进行循环。</p><p>示例效果如下<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/mesh_quadric_downsampling/4_downsampling_example.png" alt title="右侧为原始模型，左侧为化简后的模型"></p><p><span id="ref"></span></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://github.com/cmu462/Scotty3D/wiki/Simplification" target="_blank" rel="noopener">[1] Scotty3D - Simplification</a><br><a href="https://rivten.github.io/2016/11/05/surface_simplification.html" target="_blank" rel="noopener">[2] Article Study : Surface Simplification using Quadric Error Metrics</a><br><a href="https://www.cnblogs.com/shushen/p/5311828.html" target="_blank" rel="noopener">[3] 三维网格精简算法（Quadric Error Metrics）附源码</a><br><a href="http://hughchen.github.io/html/cs184/proj/index.html" target="_blank" rel="noopener">[4] Edge Collapse</a><br><a href="https://pdfs.semanticscholar.org/b8c3/ca80c94778a37545bf6b0812e07a079c6c7c.pdf" target="_blank" rel="noopener">[5] Surface Simplification Using Quadric Error Metrics</a><br><a href="http://hhoppe.com/meshopt.pdf" target="_blank" rel="noopener">[6] Mesh Optimization</a><br><a href="https://slideplayer.com/slide/4808586/" target="_blank" rel="noopener">[7] Polygonal Mesh - Data Structure and Processing</a></p>]]></content>
      
      
      <categories>
          
          <category> Algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graphics </tag>
            
            <tag> geometry </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大规模建筑内景的渲染：Interior-Mapping</title>
      <link href="/2019/09/14/implementation-of-interior-mapping/"/>
      <url>/2019/09/14/implementation-of-interior-mapping/</url>
      
        <content type="html"><![CDATA[ <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/1.0_cover.png" alt title="最终的效果图"><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Interior Mapping主要用于在物体表面利用透视错局模拟出格子结构的内部内容。虽然从外部观察起来，物体内部的构造是“真实的”，但一切渲染都没有依靠更多的模型或真实顶点。这在渲染大量模式化的内部结构中会有很大作用。<br>例如渲染高楼林立的都市时，如果要渲染每个单独的房间就会有大量的性能开销，完全的使用单一的贴图又会有些单调，这个时候就适合用Interior Mapping来伪造出建筑的外观而不让性能下降太多。<br>它的几个优点：<br>1.房间的数量不会影响framerate或内存开销<br>2.并不需要太多的额外资源就可以表现大的场景<br>3.实现上并不要求高级的shader model特性<br><a id="more"></a></p><h1 id="基本思路的实现"><a href="#基本思路的实现" class="headerlink" title="基本思路的实现"></a>基本思路的实现</h1><p>思路可以参考Joost van Dongen的论文<a href="https://pdfs.semanticscholar.org/8622/48de620efe27705af3702ab2a2c0d4ec76ec.pdf" target="_blank" rel="noopener">Interior Mapping - A new technique for rendering realistic buildings</a><br>按照Joost论文中的思路实现即可，本文不再详述。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/1.1_basic_idea.png" alt title="论文中的图示和下面代码的对应关系"><br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Reciprocal of each floor's height d</span></span><br><span class="line">float3 invert_d = _Tiling / _BoundarySize;</span><br><span class="line"></span><br><span class="line">float3 cameraPos_obj = mul(unity_WorldToObject, float4(_WorldSpaceCameraPos, <span class="number">1.0</span>)).xyz;</span><br><span class="line">float3 cameraToPixelOffset_obj = i.pos_obj - cameraPos_obj;</span><br><span class="line"></span><br><span class="line">float3 cameraStepDir_obj = step(float3(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>), cameraToPixelOffset_obj);</span><br><span class="line">float3 floorId = <span class="built_in">floor</span>(i.pos_obj * <span class="number">0.999</span> * invert_d)  + cameraStepDir_obj;</span><br><span class="line">float3 floorPos_obj = floorId / invert_d;</span><br><span class="line">float3 cameraToFloorIntersectionOffset_obj = floorPos_obj - cameraPos_obj;</span><br><span class="line"><span class="comment">// This is the ratio between the actual distance before reaching destination and the distance of pixel and camera in object space</span></span><br><span class="line">float3 ratio = cameraToFloorIntersectionOffset_obj / cameraToPixelOffset_obj;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Here the intersection coordinate has been normalized through dividing by d</span></span><br><span class="line">float2 intersectionXY_obj = (cameraPos_obj + ratio.z * cameraToPixelOffset_obj).xy * invert_d;</span><br><span class="line">float2 intersectionXZ_obj = (cameraPos_obj + ratio.y * cameraToPixelOffset_obj).xz * invert_d;</span><br><span class="line">float2 intersectionZY_obj = (cameraPos_obj + ratio.x * cameraToPixelOffset_obj).zy * invert_d;</span><br><span class="line"></span><br><span class="line">float4 ceilingCol = tex2D(_CeilingTexture, intersectionXZ_obj);</span><br><span class="line">float4 floorCol = tex2D(_FloorTexture, intersectionXZ_obj);</span><br><span class="line">float4 horizonCol = lerp(floorCol, ceilingCol, step(<span class="number">0</span>, cameraToPixelOffset_obj.y));</span><br><span class="line"></span><br><span class="line">float4 wallXYCol = tex2D(_WallXYTexture, intersectionXY_obj);</span><br><span class="line">float4 wallZYCol = tex2D(_WallZYTexture, intersectionZY_obj);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Check which face is closer to camera and pick it as the final texuture for specific pixel</span></span><br><span class="line"><span class="keyword">float</span> xLessThanZ = step(ratio.x, ratio.z);</span><br><span class="line">float4 verticalCol = lerp(wallXYCol, wallZYCol, xLessThanZ);</span><br><span class="line"><span class="keyword">float</span> ratioMin_x_z = lerp(ratio.z, ratio.x, xLessThanZ);</span><br><span class="line"></span><br><span class="line"><span class="keyword">float</span> x_zLessThanY = step(ratioMin_x_z, ratio.y);</span><br><span class="line">float4 innerCol = lerp(horizonCol, verticalCol, x_zLessThanY);</span><br></pre></td></tr></table></figure></p><p>这段按照论文思路实现的代码有几点缺陷：<br>1.墙面还没有厚度，虽然可以手动加一个外墙的mask但是，会从窗外看到一个不对齐的地面，同时也无法只通过一个厚度参数自动调整。<br>2.还没有加上sprite层（家具层）丰富室内内容<br>3.在拐角处会看到本不应该看到的墙面</p><p>本文的一些定义：<br>Block: 每个单独的房间称为一个Block<br>内腔：每个Block中不被墙体填充的部分<br>d: 代表一个Block某个方向上的长度<br>_BoundarySize: 指一个Cube Mesh的某条棱的长度<br>_Tiling: 指在某个坐标轴方向上，Mesh被切分的次数<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/0.2_conventions.png" alt title="本文中出现的一些变量图示"></p><h1 id="可配置厚度墙面的实现"><a href="#可配置厚度墙面的实现" class="headerlink" title="可配置厚度墙面的实现"></a>可配置厚度墙面的实现</h1><p>如果没有显示出墙的厚度，会有看上去错位的地板<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/2.0_without_wall_thickness.png" alt title="图片来源[6]"></p><p>我们要做的是将原本的墙面朝着某个方向推出一定距离，模拟出墙的厚度。首先计算出摄像机相关变量，方便后面确定偏移量<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">float3 cameraPos_obj = mul(unity_WorldToObject, float4(_WorldSpaceCameraPos, <span class="number">1.0</span>)).xyz;</span><br><span class="line">float3 cameraToPixelOffset_obj = i.pos_obj - cameraPos_obj;</span><br><span class="line">float3 cameraStepDir_obj = step(float3(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>), cameraToPixelOffset_obj); <span class="comment">// return 1 if it's positive, otherwise 0</span></span><br></pre></td></tr></table></figure></p><p>原始的墙面界面位置为<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">floor</span>(i.positionCopy * <span class="number">0.999</span> / _d)  + stepDir</span><br></pre></td></tr></table></figure></p><p>为了模拟墙面向内intrude，需要减去一个墙面的偏移量<code>(stepDir - float3(0.5, 0.5, 0.5)) * _WallThickness</code>之后再计算相似三角形边的比<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">float3 ratio = ((<span class="built_in">floor</span>(i.positionCopy * <span class="number">0.999</span> / _d)  + stepDir - (stepDir - float3(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>)) * _WallThickness) * _d  - cameraPos_obj) / direction;</span><br></pre></td></tr></table></figure></p><p>不过目前为止只是加上了一个墙面的偏移量，结果如下图一样<div style="width: 60%; margin: auto"> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/2.1_wrong_wall.png" alt title="本该被挡住的地方因为显示了出来，会呈现错误的透视感觉"></div><br>造成视觉上的怪异的原因是对于墙面部分，我们俯视它时依然会“穿过”水平墙面看到内部的垂直墙面，而这些uv之外的部分实际不应该被看到。</p><h2 id="判断像素是否在墙内"><a href="#判断像素是否在墙内" class="headerlink" title="判断像素是否在墙内"></a>判断像素是否在墙内</h2><p>找到问题之后，我们就需要找到每个block中，那些像素对应的是墙面上的位置。<br>首先利用floor可以找到每个block的中心位置。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">float3 floorId = <span class="built_in">floor</span>(i.vertexPos  * <span class="number">0.999</span> / _d);</span><br><span class="line">float3 centerPos_obj = (floorId + <span class="number">0.5</span>) * _d;</span><br><span class="line">float3 offsetFromCenter_obj = <span class="built_in">abs</span>(i.vertexPos - centerPos_obj) / _d;</span><br></pre></td></tr></table></figure></p><p>这里的centerPos_obj在object space中，offsetFromCenter_obj表示的是归一化后的偏移，即范围为[0,1]，代表偏移量占每个block的比例.</p><p>至于如何判定一个点是否处在墙面里，一种方法是：<br>检测在某个平面上最远的坐标分量是否超出了内cube的半径，以xy平面为例<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> max_xy = max(offsetFromCenter_obj.x, offsetFromCenter_obj.y);</span><br><span class="line"><span class="keyword">float</span> mask = step((<span class="number">1</span> - _WallThickness) * <span class="number">0.5</span>, max_xy );</span><br></pre></td></tr></table></figure></p><div style="width: 60%; margin: auto"> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/2.2_xy_bool_mask.png" alt title></div><br>同样的手法可以用到其他2个平面上，合起来就是<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> max_xy = max(offsetFromCenter_obj.x, offsetFromCenter_obj.y);</span><br><span class="line"><span class="keyword">float</span> mask = step((<span class="number">1</span> - _WallThickness) * <span class="number">0.5</span>, max_xy );</span><br><span class="line"><span class="keyword">float</span> max_xz = max(offsetFromCenter_obj.x, offsetFromCenter_obj.z);</span><br><span class="line">mask *= step((<span class="number">1</span> - _WallThickness) * <span class="number">0.5</span>, max_xz );</span><br><span class="line"><span class="keyword">float</span> max_yz = max(offsetFromCenter_obj.y, offsetFromCenter_obj.z);</span><br><span class="line">mask *= step((<span class="number">1</span> - _WallThickness) * <span class="number">0.5</span>, max_yz );</span><br></pre></td></tr></table></figure><br><br><div style="width: 60%; margin: auto"> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/2.3_all_bool_mask.png" alt title></div><br>这里mask相当于是一个AND布尔运算操作，只有在各个平面的投影中都属于“内部”中的像素才可以被称为真正的内腔，也就是会绘制墙面上的像素，这些像素的mask值为0.<br>这个过程可以想象成在三个正交的方向上对一个几何体做投影挖去不属于墙面的部分，最终剩下的白色部分就是我们所需要的墙面<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">float4 outerCol = tex2D(_outerWallTexture, i.uv);</span><br><span class="line">float4 finalCol = lerp(innerCol, outerCol, mask);</span><br></pre></td></tr></table></figure><br><br>最终的效果如<br><div style="width: 60%; margin: auto"> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/2.4_correct_wall.png" alt title></div><h2 id="使用AND还是OR"><a href="#使用AND还是OR" class="headerlink" title="使用AND还是OR"></a>使用AND还是OR</h2><p>我们在进行投影布尔运算的时候，实际上会将内部结构中的墙体一并减去。但由于我们实际上只需要最外层的mask值，所以对于立方体来说，这样的操作不会有什么问题。但是对于球体等不规则物体来说，由于我们会看到内部的结构，所以被错误减去的墙体将会出现视觉问题。</p><div style="width: 60%; margin: auto"> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/2.5_wrong_sphere.png" alt title></div><br>如果将其mask输出，就能更容易的发现问题<br><div style="width: 60%; margin: auto"> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/2.6_wrong_sphere_mask.png" alt title></div><br>本来是内部的墙面出现在了球面上，因为被不正确的减去了，所以本来应该有墙的地方就缺失了一块.<br>可能从正交视图的某个平面方向上看更容易理解<br><div style="width: 60%; margin: auto"> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/2.7_wrong_sphere_mask_top.png" alt title="这里把部分xz平面上投影形成的mask用红色的框标注出来了"></div><p>修正这个错误的思路就是从之前的AND运算变成OR运算，只要在任意方向上超出内腔的范围，就认定为进入墙体。这从直观理解上也更容易理解。<br>值得注意的是，如果用OR运算，我们只需要判断两个方向即可。这是因为第三个方向的信息变得冗余了。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> max_xy = max(offsetFromCenter_obj.x, offsetFromCenter_obj.y);</span><br><span class="line"><span class="keyword">float</span> mask = step(max_xy, (<span class="number">1</span> - _WallThickness) * <span class="number">0.5</span>);</span><br><span class="line"><span class="keyword">float</span> max_xz = max(offsetFromCenter_obj.x, offsetFromCenter_obj.z);</span><br><span class="line">mask *= step(max_xz, (<span class="number">1</span> - _WallThickness) * <span class="number">0.5</span>);</span><br><span class="line"><span class="comment">// float max_yz = max(offsetFromCenter_obj.y, offsetFromCenter_obj.z);</span></span><br><span class="line"><span class="comment">// mask *= step(max_yz, (1 - _WallThickness) * 0.5);</span></span><br><span class="line">mask = <span class="number">1</span> - mask;</span><br></pre></td></tr></table></figure></p><div style="width: 60%; margin: auto"> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/2.8_correct_sphere_mask.png" alt title="可以看到这次终于正确了。"></div><p>不过这也会带来一个潜在的问题，<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/2.9_potential_visual_bug.png" alt title><br>当tiling达到某个值的时候，墙面会恰好在立方体的边缘，这个时候，整个表面就被墙遮住了。我曾经想在shader中判断并自动做偏移（只有tiling为偶数的时候才会出现）不过后来还是决定暴露这个参数，让使用者自己决定合适的tiling。有趣的是，虽然这个问题造成了不少困扰，但是之前AND的操作方法是不会遇到这个问题的;)<br>解决方法：判断墙的边界是否超出mesh的边界，详见<a href="#culling_Wall">正确显示边角的遮挡</a></p><h1 id="制作Sprite-Layer"><a href="#制作Sprite-Layer" class="headerlink" title="制作Sprite Layer"></a>制作Sprite Layer</h1><h2 id="朴素的截面偏移层"><a href="#朴素的截面偏移层" class="headerlink" title="朴素的截面偏移层"></a>朴素的截面偏移层</h2><p>原论文中提到了制作在空房间内放置道具或者人物的思路，其实实现起来也很简单，和墙面一样是对观察深度进行一个偏移后计算交点。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Intrude XY wall along Z axis by 0.4 block length</span></span><br><span class="line">float3 spriteOffset_block = float3(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0.4</span>);</span><br><span class="line">float3 cameraStepDir_obj = step(float3(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>), cameraToPixelOffset_obj);</span><br><span class="line">float3 floorId = <span class="built_in">floor</span>(i.pos_obj * <span class="number">0.999</span> * invert_d) + cameraStepDir_obj;</span><br><span class="line">float3 spriteLayerRatio = ((floorId - spriteOffset_block) / invert_d  - cameraPos_obj) / cameraToPixelOffset_obj;</span><br><span class="line">float2 S_intersectionXY = (cameraPos_obj + spriteLayerRatio.z * cameraToPixelOffset_obj).xy  * invert_d;</span><br><span class="line">float2 S_intersectionZY = (cameraPos_obj + spriteLayerRatio.x * cameraToPixelOffset_obj).zy  * invert_d;</span><br><span class="line">float4 S_XYCol = tex2D(_SpriteTex, S_intersectionXY);</span><br><span class="line">float4 S_ZYCol = tex2D(_SpriteTex, S_intersectionZY);</span><br><span class="line"><span class="keyword">float</span> S_xLessThanZ = step(spriteLayerRatio.x, spriteLayerRatio.z);</span><br><span class="line">float4 S_verticalCol = lerp(S_XYCol, S_ZYCol, S_xLessThanZ);</span><br><span class="line"><span class="keyword">float</span> S_ratioMin_x_z = lerp(spriteLayerRatio.z, spriteLayerRatio.x, S_x_less_z);</span><br><span class="line"></span><br><span class="line"><span class="keyword">float</span> ratioMin_xyz = lerp(ratio.y, ratioMin_x_z, xzLessThanY);</span><br><span class="line"><span class="comment">// To see if it's closer than the origin wall</span></span><br><span class="line"><span class="keyword">float</span> S_isLess = step(S_ratioMin_x_z, ratioMin_xyz);</span><br><span class="line"><span class="comment">// If sprite layer is closer and the alpha is greater than 0, replace old pixel of wall by sprite layer</span></span><br><span class="line">innerCol = lerp(innerCol, S_verticalCol, S_isLess * S_verticalCol.a);</span><br></pre></td></tr></table></figure><p>不过这种方法也会有明显的问题，就是只能从一个方向上观察室内的人物或物体，从侧面和背面都能很容易的注意到是面片这一事实。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/3.1_view_different_angle.gif" alt title="从各个角度观察"></p><h3 id="支持多方向适配"><a href="#支持多方向适配" class="headerlink" title="支持多方向适配"></a>支持多方向适配</h3><p>我们可以手工指定其他面，从而正确的显示<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="comment">// If the tile's unilateral count(from the center to this tile) reach half of total tiling, means it's the side tile</span></span><br><span class="line"><span class="keyword">float</span> isSideOrFront = <span class="built_in">abs</span>(<span class="built_in">ceil</span>(i.pos_obj * <span class="number">0.999</span> * invert_d).x) / (_Tiling.x/<span class="number">2</span>) &gt; <span class="number">0.999</span> ? <span class="number">1</span>:<span class="number">0</span>;</span><br><span class="line"><span class="comment">// Pick the color from side texture</span></span><br><span class="line">float4 S_verticalCol = lerp(S_XYCol, S_ZYCol, isSideOrFront);</span><br><span class="line"><span class="comment">// Here we use the ratio of the face we decided to use in above step to overwrite the actual minimal one "S_x_less_z"</span></span><br><span class="line"><span class="keyword">float</span> S_ratioMin_x_z = lerp(spriteRatio.z, spriteRatio.x, isSideOrFront);</span><br><span class="line">float2 halfTileCount = lerp(S_intersectionXY_ori, S_intersectionZY_ori, isSideOrFront) / _Tiling.x * <span class="number">2</span>;</span><br><span class="line"><span class="comment">// Because our sprite will keep repeating, even in the place we should not see it. Luckily, we can use the time it repeats to see if it's out of the valid display region.</span></span><br><span class="line"><span class="keyword">bool</span> validSpriteRegion = <span class="number">1</span></span><br><span class="line">    * step(<span class="built_in">abs</span>(halfTileCount.y), <span class="number">1</span>) </span><br><span class="line">    * step(<span class="built_in">abs</span>(halfTileCount.x), <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">float</span> ratioMin_xyz = lerp(ratio.y, S_ratioMin_x_z, xzLessThanY);</span><br><span class="line"><span class="keyword">float</span> S_isLess = step(S_ratioMin_x_z, ratioMin_xyz) * validSpriteRegion;</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p><img src="https://public-covers-1259535704.cos.ap-guangzhou.myqcloud.com/3.2_dirs_sprites.png" alt title="可以看到效果还是不理想"></p><h2 id="类Billboard-Sprite-Layer"><a href="#类Billboard-Sprite-Layer" class="headerlink" title="类Billboard Sprite Layer"></a>类Billboard Sprite Layer</h2><p>上面的方法除了在适应不同视角上处理的很生硬，代码中也有很多硬编码的重复代码。一个比较优雅的改进方法是使用一种技术可以自动的适应不同的观察角度。所以我在这里的方法是利用billboard思想制作一个可以自动跟随摄像机的sprite</p><h3 id="传统Billboard"><a href="#传统Billboard" class="headerlink" title="传统Billboard"></a>传统Billboard</h3><p>传统的billboard思路是变换顶点坐标：将Object Space下的坐标直接赋值给View Space，即可以获得稳定不变的view位置。几乎所有的操作也都是在vertex shader中完成的<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">float4 billboardPos = mul(UNITY_MATRIX_P,</span><br><span class="line">    mul(UNITY_MATRIX_MV, float4(<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>)) <span class="comment">// 依旧要记录物体中心的位置，否则物体始终在屏幕中央</span></span><br><span class="line">    + float4(v.vertex.x, v.vertex.y, <span class="number">0.0</span>, <span class="number">0.0</span>));</span><br></pre></td></tr></table></figure></p><p>但是显然这种方法无法运用到我们这个例子上，因为其他部分的显示要依附于原始的顶点位置，另外如果我们有多个block，那么对于每个block，我们无法再分出更多的顶点来完成变换（不会考虑Gemotry Shader)</p><h3 id="物体空间内的Billboard"><a href="#物体空间内的Billboard" class="headerlink" title="物体空间内的Billboard"></a>物体空间内的Billboard</h3><p>我们的思路是在保持顶点位置不变的情况下，算出每个像素对应的立方体表面的一个点的投影坐标</p><h3 id="基础知识准备"><a href="#基础知识准备" class="headerlink" title="基础知识准备"></a>基础知识准备</h3><p>在一般的渲染管线中。最先传入的顶点数据都是模型空间下的(Object space/Model space)，经过Model Matrix，View Matrix和Projection Matrix以及Viewport Transform之后成为屏幕上的坐标。在不同的文章中，Projection Matrix的定义会有差别，也是比较容易引起误导的地方。我们这里将Projection Matrix定义为将物体从View Space(Eye Space)转换到NDC Space的矩阵。<br>这样一个完整的Projection Matrix包括两个部分，<br>第一部分是“线性”的缩放，将原本的View Frustum到近裁面为$[-Z_{near}, Z_{near}]$,但深度只有1的“相似” View Frustum。在这个Clip Space中，任意一点的属性都可以由顶点属性基于x,y,z中的任意一个进行插值而得到。<br>$$<br>\left[<br>\begin{array}{cccc}<br> x_{clip}\\<br> y_{clip}\\<br> z_{clip}\\<br> 1<br>\end{array}<br>\right ]<br>=<br>\left[<br>\begin{array}{cccc}<br> \frac{ {2n} }{ {r-l} } &amp; 0 &amp; \frac{ {r+l} }{ {r-l} }  &amp; 0 \\<br> 0 &amp; \frac{ {2n} }{ {t-b} } &amp; \frac{ {t+b} }{ {t-b} }  &amp; 0 \\<br> 0 &amp; 0                      &amp; \frac{ {-(f+n)} }{ {f-n} } &amp; \frac{ {-2fn} }{ {f-n} } \\<br> 0 &amp; 0 &amp; -1 &amp; 0 \\<br>\end{array}<br>\right ]<br>\left[<br>\begin{array}{cccc}<br> x_{view}\\<br> y_{view}\\<br> z_{view}\\<br> 1<br>\end{array}<br>\right ]<br>$$<br>这一步发生在vert shader中<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/camera-space.png" alt title="图中的是Camera Space，但Clip Space也是类似的形状,。图片来自[1]"><br>第二部分中，我们要将Clip Space通过Perspective Divide转换到NDC(Normalized Device Coordinates) Space。NDC空间是按近大远小压缩的。<br>NDC还有另外一个特点：该空间中如果要计算任意一点的属性值，直接根据Barycentric Interpolation来插值的话会因为深度的非均匀压缩而产生扭曲<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/perspective_correct_texture_mapping.jpg" alt title="中间为没有透视矫正的场景，图片来自wikipedia"><br>解决方法是应用Perspective Correction进行矫正，若已知顶点P1, P2的属性，则线段上任意一点P的值为<br>$$p=z[\frac{p_1}{z_1}(1-t) + \frac{p_2}{z_2}t]$$<br>直观的理解是先将属性按照深度压缩，然后就可以线性的插值了。详细的推导过程见<a href="https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/visibility-problem-depth-buffer-depth-interpolation" target="_blank" rel="noopener">scratchapixel</a></p><p>Perspective Divide的矩阵表示<br>$$<br>\left[<br>\begin{array}{cccc}<br> x_{ndc}\\<br> y_{ndc}\\<br> z_{ndc}<br>\end{array}<br>\right ]<br>=<br>\left[<br>\begin{array}{cccc}<br>    \frac{1}{-z_{view}}\\<br>    \frac{1}{-z_{view}}\\<br>    \frac{1}{-z_{view}}<br>\end{array}<br>\right ]^{\mathsf{T}}<br>\left[<br>\begin{array}{cccc}<br> x_{clip}\\<br> y_{clip}\\<br> z_{clip}<br>\end{array}<br>\right ]<br>$$<br>这一步在frag shader之前GPU自动进行<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/ndc.png" alt title="注意此时z轴的方向会变成相反的。 图片来自[1]"><br>如果将clip space中的属性应用到屏幕上，会因为顶点的位置是压缩过的而产生变形。</p><p>这样有了两个部分后，一个完整的Projection Matrix就可以表示为<br>$$<br>[M_{Proj}] =<br>\left[<br>\begin{array}{cccc}<br>    \frac{1}{-z_{view}}\\<br>    \frac{1}{-z_{view}}\\<br>    \frac{1}{-z_{view}}\\<br>    N/A<br>\end{array}<br>\right ]^{\mathsf{T}}<br>\left[<br>\begin{array}{cccc}<br> \frac{ {2n} }{ {r-l} } &amp; 0 &amp; \frac{ {r+l} }{ {r-l} }  &amp; 0 \\<br> 0 &amp; \frac{ {2n} }{ {t-b} } &amp; \frac{ {t+b} }{ {t-b} }  &amp; 0 \\<br> 0 &amp; 0                      &amp; \frac{ {-(f+n)} }{ {f-n} } &amp; \frac{ {-2fn} }{ {f-n} } \\<br> 0 &amp; 0 &amp; -1 &amp; 0<br>\end{array}<br>\right ]<br>$$</p><p>如果直接使用frag shader的输入中的position（通过SV_POSITION这个语义绑定(semantics binding) ）的xy分量来映射billboard的uv，我们可以得到一个屏幕空间下的映射，但是使用的其实就是类似于gl_FragCoord的屏幕坐标值，并不能适应我们后面的调整需要。另外补充一下，SV_POSITION虽然在vert shader还是Clip Space，但是在进入frag shader之前会进行Perspective Divide（在某些硬件下这部分的计算会交给frag shader，但是仍处于可编程部分之前，所以可以通俗的认为都发生在frag shader之前）从而SV_POSITION就进入了NDC也即就行了透视处理。<br>虽然Unity中DirectX和OpenGL或Vulkan对projection matrix的实现各不相同，但是他们的w分量都是$Z_{view}$(虽然Projection Matrix中$w = -Z_{view}$，但在前一步的View Matrix时已经取反了一次)，所以除以这个w分量就能将坐标压缩到NDC完成透视变换。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/3.3_unity_matrix.png" alt title><br>屏幕空间下的值只能使用NDC来插值，Clip Space下坐标和View Space成“线性”关系，和World Space成affine关系。</p><p>虽然frag shader中的输入SV_POSITION的z值已经是NDC下的，但是因为我们后面会要计算相对参考点的位置，而参考点又都没有进行透视处理，所以为了方便起见，我们统一在Clip Space进行处理，最后一步的时候再转换到NDC空间。<br>而要获得像素点在Clip Space下的坐标，我们有两种方法，<br>一种是对已经进入到ndc的坐标逆向乘以w分量从而得到Clip Space坐标。不过因为SV_POSITION本身并不属于NDC，所以我们不能通过这种方法获取除z以外的其他Clip Space中的坐标<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> depth = i.pos.z * i.pos.w;</span><br><span class="line"><span class="keyword">return</span> half4(depth, depth, depth, <span class="number">1</span>); <span class="comment">// Ouput depth visualization</span></span><br></pre></td></tr></table></figure></p><p>还有一种方法是先在vert shader中将Clip Space坐标保存成一个顶点属性，然后交由硬件插值后传入frag shader。这里的重要区别是，GPU不会对没有标记SV_POSITION的顶点属性进行Perspective Divide和ViewPort Transform，进行的是含透视矫正的插值。由于是含透视矫正的，所以对于插值的属性，它按在Clip Space的深度进行插值，也就是说它的坐标值准确的对应于Clip Space下该frag的坐标。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> depth = i.pos_clip.z;</span><br><span class="line"><span class="keyword">return</span> half4(depth, depth, depth, <span class="number">1</span>); <span class="comment">// Ouput depth visualization</span></span><br></pre></td></tr></table></figure></p><p>有意思的是，如果我们将Clip Space坐标除以了w之后就可以得到NDC空间下的屏幕坐标，可以用来当uv采样texture看看是不是如我们期望的一样。<br>核心代码如下<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">v2f</span> &#123;</span></span><br><span class="line">    float4 pos:     SV_POSITION;</span><br><span class="line">    float2 uv:      TEXCOORD0;</span><br><span class="line">    float4 pos_clip:TEXCOORD1;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">v2f <span class="title">vert</span><span class="params">(appdata_all v)</span> </span>&#123;</span><br><span class="line">    v2f o;</span><br><span class="line">    ...</span><br><span class="line">    o.pos = UnityObjectToClipPos(v.vertex);</span><br><span class="line">    o.pos_clip = UnityObjectToClipPos(v.vertex);</span><br><span class="line">    <span class="keyword">return</span> o;</span><br><span class="line">&#125;</span><br><span class="line">half4 frag(v2f i) : COLOR &#123;</span><br><span class="line">    <span class="keyword">return</span> tex2D(_MainTex, frac(i.pos_clip.xy / i.pos_clip.w));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/3.4_rotate_first_billboard.gif" alt title><p>但是我们也会注意到一个问题，这是一个“真的”billboard，uv的中心也始终在屏幕（也就是摄像机）的中央，如果将摄像机进行平移，就会失去中心点。另外，随着摄像机的拉近和拉远也没有缩放效果。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/3.5_static_scale.gif" alt title="这与其说是billboard，倒不如说更像是个用几何体的轮廓制作的Mask"></p><h3 id="让Billboard跟随物体"><a href="#让Billboard跟随物体" class="headerlink" title="让Billboard跟随物体"></a>让Billboard跟随物体</h3><p>让我们先解决第一个问题，即让billboard跟着mesh走。方法是先计算出物体模型空间下的中心在Clip Space中的位置。由于已经有了当前frag的Clip Space坐标，我们就能算出当前frag距离物体中心的偏移量（注意此刻我们仍是在Clip Space中，后面还需转换到NDC中）。如果当前frag的Clip Space坐标和物体的中心一样，那么偏移量就为0，uv也对应的为0。在有更多偏移量的地方设置相应的uv，这样就实现了uv以<strong>物体中心</strong>而不是屏幕的中心为起点向周围发散。这会是一个很大的帮助，因为我们后面会要让每个billboard sprite紧紧附在对应的block上。</p><p>不过如果uv的起点是物体的中心，那贴图的左下角（UV为(0,0)）也会是会和中心对齐，这看上去就会很奇怪。我们要做的是指定GetNdcUv计算出的uv变为（0.5，0.5），即在计算出的uv加上（0.5，0.5）的偏移（等价于将texture向（-0.5，-0.5）的方向移动）<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">float3 center_block = float3(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>);</span><br><span class="line">float3 offsetFromFloor_block = frac(<span class="number">1</span> + sign(i.pos_obj) * center_block);</span><br><span class="line"><span class="comment">// Origin we want the billboard to be in object space</span></span><br><span class="line">float3 offset_obj = sign(i.pos_obj) </span><br><span class="line">        * d * (offsetFromFloor_block + <span class="built_in">floor</span>(<span class="built_in">abs</span>(i.pos_obj * <span class="number">0.999</span>) / d));</span><br><span class="line">float4 uvOrigin_clip = UnityObjectToClipPos(float4(offset_obj.xyz, <span class="number">1.0</span>));</span><br><span class="line">float2 uv_ndc = pos_clip.xy / pos_clip.w;</span><br><span class="line">float2 uv_origin_ndc = uvOrigin_clip.xy / uvOrigin_clip.w;</span><br><span class="line"><span class="comment">// Caculate the uv offset from center in obj space</span></span><br><span class="line">uv_ndc.xy -= uv_origin_ndc;</span><br><span class="line">half4 screenTexture = tex2D(_MainTex, uv_ndc + center_block); <span class="comment">// The compensate offset here is actually incorrect since we only consider one direction.</span></span><br></pre></td></tr></table></figure></p> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/3.6_uv_correction.png" alt title><p>可以看到A1格已经到了左下角，没有完全对齐的原因是因为缩放比例还不正确。</p><p>我们也可以调节uvTiling让uv充满整个面（这个也可以自动算出，但是有时候美术的确可能需要手动调节sprite的大小）,如果想让sprite的anchor中心不再是物体的中心，也可以自己加offset细调，这会在<a href="#anchro_adjust">后面</a>提到。</p><h3 id="让Billboard带透视"><a href="#让Billboard带透视" class="headerlink" title="让Billboard带透视"></a>让Billboard带透视</h3><p>至于没有随着距离远近缩放的问题，可以通过<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv_ndc *= uvOrigin_clip.w;</span><br></pre></td></tr></table></figure></p><p>来解决，这是因为uv_ndc是在ndc下的offset，只有乘以了z才能变成Clip Space下的距离，实现uv“近小远大”，texture对应的近大远小。另外注意这里对于一个block，统一使用了中心点的w分量来做透视，这样可以保证整个面上所有的像素的深度都是一致的。虽然也可以通过与frag的w混合来实现一定程度的透视效果，但是这里就不展开了。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/3.7_perspective_correct.gif" alt title></p><h3 id="Tiled-Sprite-Layer"><a href="#Tiled-Sprite-Layer" class="headerlink" title="Tiled Sprite Layer"></a>Tiled Sprite Layer</h3><p>下一步就是实现 tilied sprite layer。<br>我们可以首先计算出每个block的边长<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> d = _BoundarySize/ _Tiling;</span><br></pre></td></tr></table></figure></p><p>同时将原始的object position也作为顶点属性传递到frag shader之后，可以计算出这属于第几个block，然后再加上半格的偏移就可以得到每个block中心的位置，要记得带上sign(i.originPos)，否则方向会是错的。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> d = _Length / _PosTiling;</span><br><span class="line"><span class="comment">// Origin we want the billboard to be in object space</span></span><br><span class="line">float3 offset_obj = sign(i.pos_obj) * d * (<span class="built_in">floor</span>(<span class="built_in">abs</span>(i.pos_obj*<span class="number">0.999</span>) / d) + float3(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>));</span><br></pre></td></tr></table></figure></p><p>再将新的offset传入后，就能看到tilied的sprite了<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/3.8_tiled_billboard.gif" alt title></p><p><span id="anchro_adjust"></span><br>目前物体的旋转中心还是在物体的中央（每个block的(0.5,0.5,0.5)处）。我们要调整的是offset，因为它是我们认为的参考点（anchor），所以还要做一步偏移操作。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Move the anchor to feet</span></span><br><span class="line">float3 center_block = float3(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>) + float3(<span class="number">0</span>, <span class="number">-0.3</span>, <span class="number">0</span>);</span><br><span class="line">float3 offsetFromFloor_block = frac(<span class="number">1</span> + sign(i.pos_obj) * center_block);</span><br><span class="line">float3 offset_obj = sign(i.pos_obj) </span><br><span class="line">    * d * (offsetFromFloor_block + <span class="built_in">floor</span>(<span class="built_in">abs</span>(i.pos_obj * <span class="number">0.999</span>) / d));</span><br><span class="line">float3 intrudeDir_obj = normalize(offset_obj - cameraPos_obj);</span><br><span class="line">float2 uv_ndc = GetNdcUv(clipPos, _UvTiling, offset_obj.xyz - _Offset.w * intrudeDir_obj));</span><br></pre></td></tr></table></figure></p> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/3.9_align_to_anchor.gif" alt title="我将anchor gizmos放到了billboard在的中心，可以看到无论如何旋转相机，billboard的uv都能和它保持相对静止"><p>为了验证我们的计算没有错误，我们可以比较虚拟billboard是否和真实的billboard有一样的显示。我在场景里放了一块传统的billboard，放置在和虚拟billboard同样的anchor点，然后旋转物体进行观察。结果可以看到两者完全重合在一起，证明了算法的准确性。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/3.10_compare_with_real_billboard.gif" alt title="你能发现藏在box中的真正的billboard吗"></p><p><img src="https://4.bp.blogspot.com/-fjxkTPOjjFY/W6YYGka4GeI/AAAAAAAAHZM/Z3cqOgvNANY76Ho3-_B81p1ZdmHa2j2DwCLcBGAs/s1600/Interior%2BMapping%2B-%2BFurniture.jpg" alt title=" 比较论文中的家具层的效果，可以看到会在某种程度上减小flat感"><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/3.11_final_result.gif" alt title="最终效果"></p><p><span id="culling_Wall"></span></p><h1 id="正确显示边角的遮挡"><a href="#正确显示边角的遮挡" class="headerlink" title="正确显示边角的遮挡"></a>正确显示边角的遮挡</h1><p>最后一步是，如果墙面正好在房间的外部一些，即我们的mesh之外一点。虽然表面上采样的点属于内腔，从正面看是不会看到遮挡的墙，但是从另一个角度看，则会看到本该被剔除的墙面。一般发生在墙面的转角处。这一点甚至在PS4 Spider-Man中都没有处理<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/4.1_wrong_corner_spider_man.png" alt title="注意画面左侧的墙面，本应该是窗户但是却显示了墙壁"><br>完整视频参考：</p><iframe width="560" height="315" src="https://www.youtube.com/embed/YQVHtlVEirs?start=39" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><p>不过要想解决这个问题并不复杂。我们只用计算出最外层的坐标阈值，超出部分一律不绘制即可。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Test if wall's z is out of box boundary</span></span><br><span class="line"><span class="keyword">float</span> zIsInsideBoundary = step(<span class="built_in">abs</span>(cameraPos_obj + ratio.z * cameraToPixelOffset_obj).z / (_BoundarySize * <span class="number">0.5</span>), <span class="number">0.999</span>);</span><br><span class="line"><span class="comment">// Test if wall's x is out of box boundary</span></span><br><span class="line"><span class="keyword">float</span> xIsInsideBoundary = step(<span class="built_in">abs</span>(cameraPos_obj + ratio.x * cameraToPixelOffset_obj).x / (_BoundarySize * <span class="number">0.5</span>), <span class="number">0.999</span>);</span><br><span class="line">...</span><br><span class="line">float4 wallXYCol = tex2D(_WallXYTexture, intersectionXY_obj) * zIsInsideBoundary;</span><br><span class="line">float4 wallZYCol = tex2D(_WallZYTexture, intersectionZY_obj) * xIsInsideBoundary;</span><br></pre></td></tr></table></figure></p> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/imp-interior-mapping/4.1_correct_corner.png" alt title="右边图中边缘多余的墙壁被剔除了"><h1 id="后面的改进"><a href="#后面的改进" class="headerlink" title="后面的改进"></a>后面的改进</h1><p>1.通过事先bake好光照，使室内的表现更加真实。计算真实的光照也是有可能的，只不过可能需要更多的操作，需要权衡一下是否真的需要。<br>2.处理好不同方向的偏移补偿，目前的uv offset补偿其实是有问题的，没有考虑顶部和底部的情况。（不过如果大楼是封顶的倒也不太要紧）<br>3.本文使用的是分开的墙面texture方法，也有些实现使用的是Cubemap。<img src="https://forum.unity.com/attachments/interiormapping-cubemap-jpg.198474/" alt title="图片来源：[8]"></p><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><p><a href="https://jsantell.com/model-view-projection" target="_blank" rel="noopener">[1] Model View Projection</a><br><a href="http://www.songho.ca/opengl/gl_projectionmatrix.html" target="_blank" rel="noopener">[2] OpenGL Projection Matrix</a><br><a href="https://pdfs.semanticscholar.org/8622/48de620efe27705af3702ab2a2c0d4ec76ec.pdf" target="_blank" rel="noopener">[3] Interior Mapping - A new technique for rendering realistic buildings</a><br><a href="https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/visibility-problem-depth-buffer-depth-interpolation" target="_blank" rel="noopener">[4] The Visibility Problem, the Depth Buffer Algorithm and Depth Interpolation</a><br><a href="http://pluspng.com/png-151110.html" target="_blank" rel="noopener">[5] Test Character Sprite</a><br><a href="http://wiki.amplify.pt/index.php?title=Unity_Products:Fake_Interiors/Manual" target="_blank" rel="noopener">[6] Unity Products:Fake Interiors/Manual</a><br><a href="http://joostdevblog.blogspot.com/2018/09/interior-mapping-real-rooms-without.html" target="_blank" rel="noopener">[7] Interior Mapping: rendering real rooms without geometry</a><br><a href="https://forum.unity.com/threads/interior-mapping.424676/" target="_blank" rel="noopener">[8] Unity Forum: Interior Mapping</a><br><a href="http://interiormapping.oogst3d.net/" target="_blank" rel="noopener">[9] Interior Mapping - A new technique for rendering realistic buildings</a></p>]]></content>
      
      
      <categories>
          
          <category> Dev </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graphics </tag>
            
            <tag> shader </tag>
            
            <tag> game </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Weekly Animation Share Vol 2</title>
      <link href="/2019/09/11/weekly-animation-share-vol-2/"/>
      <url>/2019/09/11/weekly-animation-share-vol-2/</url>
      
        <content type="html"><![CDATA[<h1 id="Egg-McMuffin-Director’s-Cut"><a href="#Egg-McMuffin-Director’s-Cut" class="headerlink" title="Egg McMuffin - Director’s Cut"></a>Egg McMuffin - Director’s Cut</h1><a id="more"></a><p><iframe name="iframe-blocked" src="https://player.vimeo.com/video/354894903" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen altimgurl="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/weekly-animation-share-vol-2/egg-mcmuffin.jpg"></iframe></p><p><a href="https://vimeo.com/354894903" target="_blank" rel="noopener">Egg McMuffin - Director&#039;s Cut</a> from <a href="https://vimeo.com/matthieubraccini" target="_blank" rel="noopener">Matthieu BRACCINI</a></p><p>这是作者Matthieu为推广麦当劳的吉士蛋麦满分而和TBWA做的广告。逼真的模拟让人看完之后真的有种非常想去点一个吉士蛋麦满分的冲动。<br>更多制作过程可以到<a href="https://www.behance.net/gallery/83279865/Egg-McMuffin-Directors-Cut" target="_blank" rel="noopener">Behance</a>查看</p><p><img src="https://mir-s3-cdn-cf.behance.net/project_modules/1400_opt_1/dc0c2d83279865.5d3db91d72f70.png" alt title="设计稿"><br><img src="https://mir-s3-cdn-cf.behance.net/project_modules/disp/5f235d83279865.5d3db91d08aa7.gif" alt title="动画WIP"><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/weekly-animation-share-vol-2/egg-mcmuffin-jump.gif" alt title="Q弹十足的鸡蛋=w="></p><h1 id="While-You-Were-Sleeping"><a href="#While-You-Were-Sleeping" class="headerlink" title="While You Were Sleeping"></a>While You Were Sleeping</h1><p><iframe name="iframe-blocked" src="https://player.vimeo.com/video/349486776" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen altimgurl="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/weekly-animation-share-vol-2/while-you-were-sleeping.jpg"></iframe><br></p><p><a href="https://vimeo.com/349486776" target="_blank" rel="noopener">While You Were Sleeping</a> from <a href="https://vimeo.com/charliestewartmotion" target="_blank" rel="noopener">Charlie Stewart</a></p><p>“Good morning!” “Good morning. I hope you slept well”…<br>一连串机械式的AI助手问答，带我们进入了这个荒芜的外太空星球里日常的一天，只不过这一次，熟悉的AI身边，缺少了些我们自己的身影…<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/weekly-animation-share-vol-2/while-you-were-sleeping-screenshot-1.jpg" alt title></p><p>随着AI一步步的进入我们的生活，比如Siri这样每天问候我们的AI，我们不禁思考他们到底是什么，他们和我们的关系又是什么？在漫漫的世界中，他们是否能一如既往的陪伴我们？<br>这部短片通过AI标志性的对话方式，以独特的视角来观察AI。既像是嘲讽AI那似乎永不停息却又无用的生命力，又像是哀叹人类丰富的创造力和情感，却不得不接受生命的短暂与脆弱。或许我们该问的不是AI是否能陪我们一直到最后，而是我们能否陪AI一直走下去…</p><h1 id="Negative-Space"><a href="#Negative-Space" class="headerlink" title="Negative Space"></a>Negative Space</h1><p><iframe name="iframe-blocked" src="https://player.vimeo.com/video/345922827" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen altimgurl="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/weekly-animation-share-vol-2/negative-space.jpg"></iframe></p><p><a href="https://vimeo.com/345922827" target="_blank" rel="noopener">Negative Space</a> from <a href="https://vimeo.com/tinyinventions" target="_blank" rel="noopener">Tiny Inventions</a></p><p>主人公Sam虽然不善言辞，打包行李却很拿手。毛巾卷成卷，衣服按规则叠好，袜子分类放在箱子顶部，一根皮带绕在箱子边缘，最后才放入皮鞋。这一切都源自他那总是出差在外的父亲。当他还是个孩子的时候就已经耳濡目染，等他稍微长大些的时候，就已经能帮助忙碌的父亲打包行李。平日里不像其他父子可以有很多时间交流，但12岁那年简单的打包却换来了父亲的一句”Perfect”。<br>时隔多年，Sam再一次打包好行李，去最后见一次教会自己这一切的那个人…</p><p>这部定格动画短片是一个基于Ron Koertge创作的150字诗。与一般的父子不同，片中的主人公与自己平日很少见面的父亲的联系则是通过打包行李来维系和一步步加深的。<br>打包的过程并不那么惊心动魄，甚至一点都不有趣，可是总是生活中这样的小细节让人感到美好。整部片子的质量很高，不仅仅是一部简单的逐帧动画，画面自然的衔接和丰富的想象力也大大的扩展了诗本来的内容。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/weekly-animation-share-vol-2/negative-space-screenshot-1.jpg" alt title></p><p>本片的创作者是美国的Max Porter和日本的Ru Kuwahata，他们是一对动画创作搭档，他们创办了<a href="https://www.tinyinventions.com/main/who-we-are/" target="_blank" rel="noopener">Tiny Inventions</a>，是获奥斯卡提名的动画导演，擅长用不同媒介叙事，其中以定格动画最为出名。这次的Negative Space也获得了多达127个大大小小奖项。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/weekly-animation-share-vol-2/negative-space-interview.jpg" alt title="Ru Kuwahata和Max Porter"><br>关于这部动画的创造过程，可以查看<a href="https://vimeo.com/238590794" target="_blank" rel="noopener">这里</a>。很有意思的是，Kuwahata的父亲就曾经是一位飞行员，所以他对打包行李的心得也让女儿在创作本片的时候得到了很多共鸣。</p><p><a href="https://wordsfortheyear.com/2014/12/19/negative-space-by-ron-koertge/" target="_blank" rel="noopener">Negative Space</a><br>by Ron Koertge</p><p>My dad taught me to pack: lay out everything. Put back half. Roll things that roll. Wrinkle-prone things on top of cotton things. Then pants, waist-to-hem. Nooks and crannies for socks. Belts around the sides like snakes. Plastic over that. Add shoes. Wear heavy stuff on the plane.</p><p>We started when I was little. I’d roll up socks. Then he’d pretend to put me in the suitcase, and we’d laugh. Some guys bond with their dads shooting hoops or talking about Chevrolets. We did it over luggage. By the time I was twelve, if he was busy, I’d pack for him. Mom tried but didn’t have the knack. He’d get somewhere, open his suitcase and text me—“Perfect.” That one word from him meant a lot.</p><p>The funeral was terrible—him laid out in that big carton and me crying and thinking, Look at all that wasted space.</p><script type="text/javascript" src="/js/src/blocked-video.js"></script>]]></content>
      
      
      <categories>
          
          <category> Motion </category>
          
      </categories>
      
      
        <tags>
            
            <tag> anime </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Weekly Animation Share Vol.1</title>
      <link href="/2019/09/07/weekly-animation-share-vol-1/"/>
      <url>/2019/09/07/weekly-animation-share-vol-1/</url>
      
        <content type="html"><![CDATA[<p>作为第一期的每周动画分享（会有几期也不知道…），先简单介绍下做这个系列的动机。之前经常会逛<a href="http://animetaste.net/" target="_blank" rel="noopener">AT! 品赏阿尼墨</a>，通过这个平台看到过不少优秀的作品。但因为网站已经很久没更新了，而如今的动画公众号也缺少一些独立短片的推荐，所以出于个人兴趣爱好，决定（不）定期的更新一些自己发现的有意思的动画短片。这次的三个视频都来自vimeo，由于被墙了，所以国内小伙伴可能看起来不太方便，目前只好提供截图封面，后面我会思考下如何解决这个问题…</p><h1 id="CAT-DAYS-ねこのひ"><a href="#CAT-DAYS-ねこのひ" class="headerlink" title="CAT DAYS / ねこのひ"></a>CAT DAYS / ねこのひ</h1><a id="more"></a><p><iframe name="iframe-blocked" src="https://player.vimeo.com/video/296302547?color=ef1900&title=0&byline=0&portrait=0" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen altimgurl="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/weekly-animation-share-vol-1/cat-days.jpg"></iframe></p><p><a href="https://vimeo.com/296302547" target="_blank" rel="noopener">CAT DAYS / ねこ の ひ / Neko no Hi</a> from <a href="https://vimeo.com/user45689947" target="_blank" rel="noopener">Jon Frickey</a></p><p>这一部2018年的动画获得过多个动画节的大奖，讲述的是一个叫Jiro的小男孩在某一天得了一场病。当他爸爸带他去看病的时候，医生带给了他们一个“惊人”的消息，男孩竟然可能是猫。在接下来等待最终鉴定结果的几天里，男孩和爸爸都试图接受这个身份的转变…<br>这部片子很容易让人联想到细田守的动画<a href="http://www.ookamikodomo.jp/index.html" target="_blank" rel="noopener">《狼的孩子雨和雪》(おおかみこどもの雨と雪)</a>，同样是讲述的人的动物化。他们之所以能将生活中本不可能真实发生的事，描绘的非常自然，得益于他们能将身份认同/身份代入这一点用巧妙的方式代入到故事的主体中。人固然是人本身，可是其他动物的天性同样反映在人的身上，尤其是当一个人还是个孩子的时候。通过将人和动物的双重形象进行对比，身份的转变，孩子的成长这一主题得以通过一个更为突出的过程体现了出来。<br>这样一部日系满满的动画，没想到竟然出自一位来自德国的40岁的大叔动画导演<a href="https://www.jonfrickey.com/about" target="_blank" rel="noopener">Jon Frickey</a><br><img src="https://m.media-amazon.com/images/M/MV5BM2Q0N2IzY2ItNWEwYy00NGU3LWIxNTEtM2Y3MDk0Y2ExMjc0XkEyXkFqcGdeQXVyODI5NTk1NzI@._V1_UY317_CR11,0,214,317_AL_.jpg" alt="Jon Frickey"></p><h1 id="DOOOOUGH-YEAH"><a href="#DOOOOUGH-YEAH" class="headerlink" title="DOOOOUGH YEAH!"></a>DOOOOUGH YEAH!</h1><p><iframe name="iframe-blocked" src="https://player.vimeo.com/video/236225252?color=ef1900&title=0&byline=0&portrait=0" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen altimgurl="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/weekly-animation-share-vol-1/doooough-yeah.jpg"></iframe></p><p><a href="https://vimeo.com/236225252" target="_blank" rel="noopener">DOOOOUGH YEAH!</a> from <a href="https://vimeo.com/wesleyfuh" target="_blank" rel="noopener">Wesley Fuh</a></p><p>这是一个有趣的动画短片，讲述的是一个诞生于边角料的瘦小面团，看到其他的面团经过烘焙都成为了“肌肉猛男”(beautiful bread 笑)，迫不及待的想跻身他们的行列，结果机缘巧合之下，变成了椒盐卷饼(brezel)<br>这个动画的亮点在于很有创意。将烤熟的菠萝面包想象成有六块腹肌的健身猛男，而涂上的黄油酱更是成为了耀眼的金光，难怪没有一个面团甘于平庸。幸好结果是正面的，因为边角料面团成为了更beautiful的存在（。<br>另外，该片的声效似乎都是作者自己配的，倒是很可爱。最后，大家可能都会记住那一声声的”Dooough Yeah”了吧</p><h1 id="The-Year-of-the-Pig"><a href="#The-Year-of-the-Pig" class="headerlink" title="The Year of the Pig"></a>The Year of the Pig</h1><p><iframe name="iframe-blocked" src="https://player.vimeo.com/video/315958054?color=ef1900&title=0&byline=0&portrait=0" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen altimgurl="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/weekly-animation-share-vol-1/the-year-of-the-pig.jpg"></iframe></p><p><a href="https://vimeo.com/315958054" target="_blank" rel="noopener">The Year of the Pig</a> from <a href="https://vimeo.com/ryanbooth" target="_blank" rel="noopener">Ryan Booth</a></p><p>这部小短片严格意义上讲并不好分类。从作者的简单介绍中，他也形容它为”just a collection of moments…”。<br>短片记录的是纽约庆祝农历猪年时的场景以及生活中的一些画面，全片平淡却又有让人感动的小细节，宛如一个人在静静的回忆温暖的瞬间。整体的画面经过电影调色，体现出一种冬日里一股温暖的感觉，也颇有中国80,90年代电影的感觉。短片中的相机抖动既是转场的需要，也为画面增加了不少生活的真实感。<br>不同于中国人庆祝新年时惯用的喜庆音乐，全片的背景音乐都非常祥和而安静，让我们这些来自中国的人们感到有些好奇和陌生。新鲜之余，也从中能窥探出不同文化的人们对未来期待的不同表达。<br>带给我类似感受的还有<a href="https://www.imdb.com/title/tt0401711/" target="_blank" rel="noopener">《巴黎，我爱你》(Paris, je taime)</a>，同样没有过于复杂的剧情，更多的是纪录片似的喃喃自语</p><script type="text/javascript" src="/js/src/blocked-video.js"></script>]]></content>
      
      
      <categories>
          
          <category> Motion </category>
          
      </categories>
      
      
        <tags>
            
            <tag> anime </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Notes on ddx/ddy</title>
      <link href="/2019/08/25/Notes-on-ddx-ddy/"/>
      <url>/2019/08/25/Notes-on-ddx-ddy/</url>
      
        <content type="html"><![CDATA[<h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><p>ddx/ddy用于返回屏幕空间中某一值关于x,y方向上的偏导数。它只可以用于fragment program中，参数必须来自fragment的输入。<br>HLSL对<a href="https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl-ddx" target="_blank" rel="noopener">ddx的定义</a>：Returns the partial derivative of the specified value with respect to the screen-space x-coordinate.<br>GLSL中对应的函数为<a href="https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/dFdx.xhtml" target="_blank" rel="noopener">dFdx/dFdy</a></p><a id="more"></a><h1 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h1><p>在triangle rasterization阶段，GPU会对多个像素实例同时运行fragment shader。在最细的程度上，它将会通过SIMD同时跑32-64个像素（实例）。在这些像素中，又会被划分成2 * 2的小组（又被称为quad-fragments），所以每个组会有四个相邻的像素，这样SIMD指令就能同时处理屏幕上2 * 2 = 4个像素了。<br>每个像素中的值都来自于vertex program或其他步骤输出之后得到的插值，所以对于这些值来说，在进入到fragment shader之前就完成了计算，这些是可以并行计算得到的。所以在fragment shader中运行ddx(vertexOuput)的时候，就能知道这个插值的变化导数。</p><p>fragment shader之所以能够访问到相邻像素的数据（即SIMD的不同lanes/thread，每个lanes/thread都处理一个像素），是因为GPU利用了(quad) swizzle进行了跨lanes的数据访问<br><img src="https://anteru.net/images/2018/pixel-crosstalk.svg" alt title="来源：[7]"></p><p>对于AMD的GCN，<code>ds_swizzle_b32</code>指令的offset field是留给<code>ds_pattern</code>的。它有两种模式<a href="#ref">[10]</a>：</p><blockquote><ul><li><strong>Quad-permute mode (QDMode)</strong>: Each of the four adjacent lanes can access each other’s data, and the same switch applies to each set of four. The ds_pattern LSBs directly encode the element ID for each lane.</li><li><strong>Bit-masks mode (BitMode)</strong>: This mode enables limited data sharing within 32 consecutive lanes. Each lane applies bitwise logical operations with constants to its lane ID to produce the element ID from which to read. Constants are encoded in ds_pattern .</li></ul></blockquote><p><img src="https://gpuopen.com/wp-content/uploads/2016/08/ds_pattern.png" alt title="对应的图示"><br>QDMode模式会更清晰一点<br><img src="https://gpuopen.com/wp-content/uploads/2016/08/qdmode.png" alt title="一个简单的例子：分别将原来的0,1,2,3位变成2,1,3,3位"><br><img src="https://gpuopen.com/wp-content/uploads/2016/08/ds-swizzle-b32.png" alt title="过程示意图"></p><h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><h2 id="1-计算Lod或各向异性-Anisotropy"><a href="#1-计算Lod或各向异性-Anisotropy" class="headerlink" title="1.计算Lod或各向异性(Anisotropy)"></a>1.计算Lod或各向异性(Anisotropy)</h2><p>因为mipmap level需要计算fragmentInput.uv的导数，即相邻像素之间对应纹素的差距。过程是将屏幕坐标的点映射到uv平面上，然后计算出距离。取出最大的一个距离L，并做$log_2⁡L$。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/ddx/mipmap_lod.png" alt title="计算mipmap level图示，来源：[5]"><br>其含义就是如果uv平面中采样点很稀，相应的du/dx或其他的值就比较大，L也相应的比较大。这种情况说明Minification了，很多纹素就堆在了一个像素里。我们实际上用不到这么多纹素，于是一个很高级别的mipmap(更模糊的）就可以用来节省渲染的负担，也可以避免出现锯齿。<br><img src="https://i.stack.imgur.com/VJEqW.png" alt title="计算uv的偏导的图示，来源：[1]"></p><h2 id="2-计算面法线"><a href="#2-计算面法线" class="headerlink" title="2.计算面法线"></a>2.计算面法线</h2><p>在 FragShader 中，调用<code>ddx(i.position)</code>, 和<code>ddy(i.position)</code>可以求出相邻的2 个像素之间座标的差值，即两个像素在三角面上采样的点所构成的向量。下面图中的红色和绿色2个向量即为ddx,ddy所返回的向量<br><img src="http://album.sina.com.cn/pic/002hBfPnzy7dvLft6NX99" alt title="来源：[2]"></p><p>而这2 个向量都在这个三角形的平面上，那么<br><code>normal = normalize(cross(ddx(pos), ddy(pos)))</code><br>就可以求出的面的法线，但是这里要注意，在 HLSL 或者Unity shader里要写成normalize(cross(ddy(pos), ddx(pos))) , 不然法线是反向的。这个是由于左右手座标系引起的。</p><h1 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h1><p>嵌套使用ddx(p)或ddy(p)可能导致undefine的值，如ddx(ddx(p))或ddx(ddy(p))。<br>同时，程序假设参数p是连续的。对于嵌在flow-control代码段的值，因为不是每一个在quad-fragment中的片段都会执行同样的branch，所以结果也是undefine的<br>ddx/ddy分为coarse版本和fine版本。如果直接使用ddx，等价于ddx_coarse（可以看做alias).<br><a href="https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/ddx-coarse" target="_blank" rel="noopener">ddx_coarse</a>和<a href="https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/ddx-fine" target="_blank" rel="noopener">ddx_fine</a>对于同一组2*2的quad-fragment的四个像素，他们的偏导数都将会是一样。这两个函数需要Shader Model 5的支持<a href="#ref">[4]</a></p><p>其他相关函数：<code><a href="https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl-fwidth" target="_blank" rel="noopener">fwidth(p)</a> = abs(ddx(p)) + abs(ddy(p))</code></p><p><span id="ref"></span></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://gamedev.stackexchange.com/a/130933" target="_blank" rel="noopener">[1] What are screen space derivatives and when would I use them?</a><br><a href="http://www.aclockworkberry.com/shader-derivative-functions" target="_blank" rel="noopener">[2] An introduction to shader derivative functions | A Clockwork Berry</a><br><a href="https://gamedev.stackexchange.com/a/62650" target="_blank" rel="noopener">[3] What does ddx (hlsl) actually do?</a><br><a href="https://fgiesen.wordpress.com/2011/07/10/a-trip-through-the-graphics-pipeline-2011-part-8/#comment-1990" target="_blank" rel="noopener">[4] A trip through the Graphics Pipeline 2011, part 8</a><br><a href="http://15462.courses.cs.cmu.edu/spring2018/lecture/persp/slide_055" target="_blank" rel="noopener">[5] [CMU 15462] Lecture 7: PerspectiveTexture</a><br><a href="https://catlikecoding.com/unity/tutorials/advanced-rendering/flat-and-wireframe-shading/" target="_blank" rel="noopener">[6] Flat and Wireframe Shading Derivatives and Geometry</a><br><a href="https://anteru.net/blog/2018/more-compute-shaders/" target="_blank" rel="noopener">[7] More compute shaders</a><br><a href="https://developer.nvidia.com/gpugems/GPUGems2/gpugems2_chapter35.html" target="_blank" rel="noopener">[8] [GPU Gems 2] 35.2.4 The Swizzle Operator</a><br><a href="https://developer.nvidia.com/reading-between-threads-shader-intrinsics" target="_blank" rel="noopener">[9] [Reading Between The Threads: Shader Intrinsics] Fragment Quad Swizzle - Data Exchange and Arithmetic</a><br><a href="https://gpuopen.com/amd-gcn-assembly-cross-lane-operations/" target="_blank" rel="noopener">[10] [AMD GCN Assembly: Cross-Lane Operations] The Swizzle Instruction</a></p>]]></content>
      
      
      <categories>
          
          <category> Theory </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graphics </tag>
            
            <tag> shader </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>制作不使用贴图的水滴特效</title>
      <link href="/2019/07/31/raindrop-effect/"/>
      <url>/2019/07/31/raindrop-effect/</url>
      
        <content type="html"><![CDATA[<p>Sorry, currently unavailable…</p><p>Hopefully, it will come back soon ;)</p>]]></content>
      
      
      <categories>
          
          <category> Dev </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graphics </tag>
            
            <tag> shader </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从像素之间谈起：像素游戏的画面增强（下）</title>
      <link href="/2017/07/03/from_pixel_to_screen_2/"/>
      <url>/2017/07/03/from_pixel_to_screen_2/</url>
      
        <content type="html"><![CDATA[<p>上篇见 <a href="/2017/07/02/from_pixel_to_screen_1/">从像素之间谈起：像素游戏的画面增强（上）</a></p><h1 id="其他可能的改进"><a href="#其他可能的改进" class="headerlink" title="其他可能的改进"></a>其他可能的改进</h1><h2 id="投影增强"><a href="#投影增强" class="headerlink" title="投影增强"></a>投影增强</h2><p>前面我们在进行扩散投影模拟的时候，是同时对周围八个点进行采样，但是事实上，有时为了控制投影的方向，可以只对一侧的点进行采样<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/sample_weight_partial.png" alt title><br><a id="more"></a><br>如图所示，只需要对右下角的五个格子采样，就可以模拟出左上角的光照。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/unilateral_sample.png" alt title><br>这样造成的效果是亮的部分会凸起，暗的部分会产生凹陷的效果<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/darkness_offset.png" alt title><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/lightness_offset.png" alt title></p><h2 id="函数的拟合"><a href="#函数的拟合" class="headerlink" title="函数的拟合"></a>函数的拟合</h2><p>前面在计算相邻点的加权颜色值时，用到了一个指数函数。指数函数的效果的确很好，考虑到在某些平台上exp的消耗可能有点大。另外，任意两个像素之间的欧几里得距离不会超过2.3个像素，所以我们尝试对函数进行一个拟合，如0.926+1.441x + 0.6578x^2 + 0.0417x^4<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/approx_1.jpg" alt title><br>其实我们还可以将把它化成1/(7x^2 +1)，效果也还可以，只是无论是哪种情况，在PC上测试差距并不明显（也有可能适得其反）<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/approx_2.png" alt title></p><h2 id="扫描线"><a href="#扫描线" class="headerlink" title="扫描线"></a>扫描线</h2><p>考虑到有些游戏中，会出现一些因为曝光过度而无法显示扫描线的情况。于是，我们就需要对扫描线进行加强：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> limit = <span class="number">1</span> - step(<span class="number">257.0</span>, min(frac(i.pixel_no.x), <span class="number">1</span>- frac(i.pixel_no.y)) * _MainTex_TexelSize.z);</span><br><span class="line"><span class="keyword">float</span> bright = Luminance(out_color);</span><br><span class="line"><span class="keyword">return</span> fixed4(out_color *(<span class="number">1.8</span> - limit * bright * bright * <span class="number">0.89</span>), <span class="number">1.0</span>);</span><br></pre></td></tr></table></figure></p><p>但是对于某些偏暗的游戏，如果为了提高整体亮度，而扫描线同时也强化的很厉害，那么就会导致“碳化”<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/Overexposed.png" alt title="中间的白色由于亮度过高，在补偿的时候会显得非常暗"><br>虽然这样的扫描线加强在其他场合正是我们需要的，但在这里只会让画面变得很脏。关于这个问题并没有很好的解决方案，这需要根据不同游戏对参数做出调整。作为游戏开发，如果美术风格及早的确定，颜色的选择有所参照，将会对程序的优化有极大的帮助。而2D像素游戏由于很少受光照影响，再加上像素画本身也极其依赖于palette，所以如果palette控制的好，是可以根据其调试出一个很好的状态的。</p><p>由于目前只用针对一款游戏，所以上面的手工调整可以接受。如果我们需要大量的调整，我在想，可能还有一种思路是像tone mapping一样，将亮度映射在一个合理的区域内，这样既保留了细节又处理了边界状况。</p><h2 id="Tactics-Ogre的特殊处理"><a href="#Tactics-Ogre的特殊处理" class="headerlink" title="Tactics Ogre的特殊处理"></a>Tactics Ogre的特殊处理</h2><p>刚开始我为Taactic Ogre（中文译为：皇家骑士团）写shader的时候，出现了一个问题。由于很容易知道psp的分辨率是480*272，我就将其硬编码到shader中。但是却出现了一些意想不到的状况。在横坐标方向上，扫描线的分布不均匀。由于是周期性的，并且随着窗口的扩大问题更为严重，我最开始猜测是模拟器的精度出现了问题，我查了下changelog也的确提到了这个问题，只是我使用的版本应该已经修复了这个问题。另外，我测试了其他的游戏，发现一切都很正常，如果真的是精度问题，不该只出现在这一款游戏上。查看了整个render过程后发现Tactics Ogre中有些地方与其他游戏做的不同，比如<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/ToScreen5.png" alt title="注意纹理右侧的黑边"><br>Tactics Ogre在draw顶部的滚动文本时，并不会对其裁剪，而是放到了第二个color pass里才进行裁剪<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/psp_firstpass_cut.png" alt title><br>不过ppsspp模拟器提供了u_texelDelta这样一个uniform，我们可以利用它得知当前输入纹理的resolution：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vec2 c_resolution = <span class="number">1.0f</span> / u_texelDelta;</span><br></pre></td></tr></table></figure></p><p>这样，即使在某些场景中，屏幕的分辨率发生变化，我们也能够保证显示正确的扫描线。<br><br></p><h1 id="最终PSP模拟器效果图"><a href="#最终PSP模拟器效果图" class="headerlink" title="最终PSP模拟器效果图"></a>最终PSP模拟器效果图</h1><p>在这里给出自己制作的在PSP模拟器上的最终效果，请放大后观察<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/zipped_To1.png" alt title><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/zipped_To2.jpg" alt title><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/zipped_To3.jpg" alt title><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/zipped_To4.jpg" alt title><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/zipped_To5.jpg" alt title><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/zipped_To6.jpg" alt title><br><br></p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>本文主要讨论了针对细像素游戏的画质增强，但是这并不意味着像素游戏的增强方式只有一种，相反，光是<a href="http://filthypants.blogspot.jp/2015/04/more-crt-shaders.html" target="_blank" rel="noopener">这里</a> 就提到多种后期特效。我们也无法说哪种效果比另一种更好。更多的时候，还是需要根据对游戏的定位来定制自己的后期特效，从而让画面为游戏核心服务。程序和美术之间的沟通是否充分也是能否有效的构建出成功的游戏画面中很重要的一个因素。</p><p>最后，你们觉得这是一篇讨论像素游戏中画面增强的文章吗？<br>不，不是的，我只是在安利Tactics Ogre :P</p><p>另：为防止图床炸裂，请勿随意转载:)</p>]]></content>
      
      
      <categories>
          
          <category> Dev </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graphics </tag>
            
            <tag> shader </tag>
            
            <tag> game </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从像素之间谈起：像素游戏的画面增强（上）</title>
      <link href="/2017/07/02/from_pixel_to_screen_1/"/>
      <url>/2017/07/02/from_pixel_to_screen_1/</url>
      
        <content type="html"><![CDATA[<p>由于文章太长，我将最初的文章拆成两个部分，下篇见 <a href="/2017/07/03/from_pixel_to_screen_2/">从像素之间谈起：像素游戏的画面增强（下）</a></p><h1 id="无所不在的像素画"><a href="#无所不在的像素画" class="headerlink" title="无所不在的像素画"></a>无所不在的像素画</h1><h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><p>随着分辨率的普遍提高，我们已经告别了依赖于简陋像素来表现游戏画面的年代。但还是有不少人像我一样沉迷于像素美术和游戏。如今到处可以都可以看到的各式像素作品，虽然大多被直接称呼为像素画，但实际上已经分化为很多分支，简单的将其归类为像素作品未免太含糊。在开始正文之前我先将他们粗粗的分个类。一些比较常见的代表如：</p><ol><li>大颗粒像素，此类像素作品一般细节较少，人物符号化或者抽象化。同时还可能出现非像素元素，如光晕，渐变 <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/large_scale_pixel.jpg" alt title="单键Bob，一个颇为爽快的flash游戏"><a id="more"></a></li><li><p>粒度较小的像素画，主要还是色块化，边缘并没有强化。 <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/dragon_den.gif" alt title="HGSS中的Dragon Den"></p></li><li><p>强化边缘和高光，细节丰富，但是普遍尺寸较小。 <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/small_scale_pixel.png" alt title="Drill Dozer截图"></p></li></ol><p>另外，在一些UI图标的绘制过程中，由于图标较小，也同样采用像素点绘的方式。因为它平时也不会被称为像素画，所以这里也不讨论。</p><p>其中第3种是我在本文中将着重讨论的。<br>这类像素图可能和平时所提到的像素图差的最远，因为它并不是为了做出像素化效果而诞生的。相反它是游戏机在分辨率和色板支持加强之后的产物（光是从GB到GBC，支持的色深就从2位变成了15位）。在这方面，任天堂算是是做到了极致（也可能因为任天堂的主机的屏幕天生小的缘故）这类像素画在抗锯齿（伪），光照，色彩的调和的方面很有特点（这篇文章中不细说）</p><h2 id="再现像素画"><a href="#再现像素画" class="headerlink" title="再现像素画"></a>再现像素画</h2><p>就GBA而言，分辨率为240 *160，但我们现在再制作像素的游戏时，玩家一定不会接受在这么小的一个屏幕上去玩游戏。一个是因为眼睛看的太累（长大后眼睛都变差了…）。另一方面，考虑到像素画的成本，也不建议针对一个1080p的屏幕进行逐像素绘画。为了满足一些玩家想要的像素的效果，一个最简单直接的方法就是将画面放大。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/small_scale_pixel_zoomed.png" alt title="这幅图放大了3倍之后，也许会更容易于将它认为是像素画风"></p><p>虽然这种方法省时省力，但是也会带来一个问题。在绘制像素画中的曲线时，由于一般不对线条使用反走样（会让画面变脏）来抗锯齿。在分辨率较低的时候，像素的边缘可以帮助人们识别且很难注意到异样，但当画面放大后，这些边缘就会显得粗糙不堪。这也是像素画风被一些人所诟病的原因。</p><p>为此，包括ppsspp在内的模拟器中，会内置不少shader来对图像进行后期处理。对于2D图像来说，具体方法包括xBRZ等滤镜来平滑放大图像（xBRZ对2D像素放大会产生平滑而舒适的效果，但是这会损失像素的特征），增加crt, 扫描线等后期特效将像素画做旧。当然，你也可以利用物理的手段将信号输出到CRT屏幕上，参考<a href="http://wavebeam.blogspot.jp/2016/01/a-beginners-guide-to-best-retro-gaming.html" target="_blank" rel="noopener">这里</a><br>另外，<a href="https://blz.la/rgb/gaming_crt.html" target="_blank" rel="noopener">这篇文章</a> 中讲述了一些crt效果的来源，也讨论了很多细节问题。一个简单的对比图： <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/metal_slug.jpg" alt title="from: http://www.neogaf.com/forum/showthread.php?p=236239524"><br>常见的效果如下<br><img src="http://i58.tinypic.com/2lnu2b9.png" alt="尝试翻墙显示" title="from: http://shmups.system11.org/viewtopic.php?f=6&t=51298&start=30" width="50%"><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/geom.jpg" alt title="注意屏幕的扭曲，这其实是crt的物理性质决定的"><br><img src="http://abload.de/img/royale0iu4f.png" alt="尝试翻墙显示" title="注意像素的膨胀" width="50%"></p><p>虽然实现方法不同，但总的来说都是在像素之间增加了隔断，人们的大脑会趋向为这种断裂解释理由，自动为图像进行内部平滑处理。这就和我们凑近屏幕看游戏画面但是不会觉得画面模糊的原因类似。另一方面，因为扫描线的存在，画面的层次感也可以体现出来，使得画面更加可信。甚至连Her Story中都为了剧情的需要用些crt效果。<br><a href="http://filthypants.blogspot.jp/2015/04/more-crt-shaders.html" target="_blank" rel="noopener">这篇文章</a>里介绍了大量的post processing shader，很有借鉴意义。<br><br></p><h1 id="一个shader的实现思路"><a href="#一个shader的实现思路" class="headerlink" title="一个shader的实现思路"></a>一个shader的实现思路</h1><p>本文的后期特效将主要适用于前面所述的第三种情况，也即通过临近采样的方式放大图像而达到加强像素化的目的。更多的模拟LCD屏幕而不是CRT屏幕，所以一些包括屏幕扭曲，通道分离的效果在本文中将不会涉及。本文会利用psp模拟器，将扫描线效果应用到Tactics Ogres（中文译为：皇家骑士团）上。<br>我主要从两方面完成对像素图的画面增强：1.利用微小的分割线来分隔开像素，让人们产生像素相连的错局。2.利用低通滤波器稍许的平滑像素边界（但是不宜平滑太多，不然会失去像素风格的特点）</p><p>为了统一，后面的演示代码都用CG来写，输入的纹理尺寸为512 x 384</p><h2 id="格子的分割"><a href="#格子的分割" class="headerlink" title="格子的分割"></a>格子的分割</h2><h3 id="硬分割"><a href="#硬分割" class="headerlink" title="硬分割"></a>硬分割</h3><p>首先，将像素放大了2倍之后，实际看到的一个“像素 pixel”（叫纹素 texel更为贴切）是2 x 2个像素。虽然我们想营造出的效果是让玩家觉得游戏的像素与像素之间产生了间距，但除了在原先的一个像素上通过勾画边缘来实现分割，我们并不能真的将像素之间创造出空格。这步操作之后，最小单位仍然是像素。下图所示的分别是每2个像素进行一次分割和每4个像素进行一次分割的图示。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/hard_separate_1.png" alt title="每两格有一个明暗变化周期"><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/hard_separate_2.png" alt title="每四格有一个明暗变化周期"><br>对于后期特效来说，输入的纹理为camera input，上图是1 texel对应 4 pixel，而下面是1 texel对应 16 pixel。<br>为了找到分割的位置，需要能够区分一个纹素所对应的像素。方法并不复杂, 若一个纹素拆分为4*4个像素，可以在顶点着色器上输出如下vec2：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">o.pixel_no = float2(o.uv.x * _MainTex_TexelSize.z, o.uv.y * _MainTex_TexelSize.w) * <span class="number">0.25</span>;</span><br></pre></td></tr></table></figure></p><p><code>_MainTex_TexelSize</code> 是内置uniform，记录输入纹理的相关信息，其中zw分量即为宽和高。对于ppsspp模拟器，可以通过 <code>u_texelDelta</code> 来计算屏幕的resolution，后面会提到。<br>有了pixel_no的信息，我们就可以在片段着色器里进行插值了：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">fixed4 <span class="title">Pass_Scanline</span><span class="params">(float2 uv)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">float</span> column = <span class="number">4</span>;</span><br><span class="line">        float2 pixel_no = </span><br><span class="line">            frac(float2(uv.x * <span class="number">1024.0</span>, uv.y * <span class="number">768</span>) * _ScreenScale / column);</span><br><span class="line">        <span class="keyword">if</span>(pixel_no.x &lt; <span class="number">1</span> / column || pixel_no.y &lt; <span class="number">1</span> / column)</span><br><span class="line">            <span class="keyword">return</span> PREVIOUS_PASS(uv) * <span class="number">0.5</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> PREVIOUS_PASS(uv);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>其中PREVIOUS_PASS是一个宏，用来嵌套伪multi-pass，这里的PREVIOUS_PASS可以简单的理解为上一个获取纹理的值的pass。这里当column为4的时候，一个纹素对应的四个像素的pixel_no的x分量分别为1/8, 3/8, 5/8, 7/8，我们可以利用这个信息来判断究竟哪个像素是这个纹素的边缘。<br>硬分割虽然完成了对像素的分割，但是效果比较生硬。玩家感受到的不是从屏幕上反映的图像，而更像是罩上了网格的图像。这也和asset store上的<a href="https://www.assetstore.unity3d.com/en/#!/content/73708" target="_blank" rel="noopener">这个效果</a>类似。</p><h3 id="丰富分割细节"><a href="#丰富分割细节" class="headerlink" title="丰富分割细节"></a>丰富分割细节</h3><p>硬分割的效果不理想，于是很自然的想到为这个边缘添加一些过渡效果是否会好一点呢？答案是肯定的。另外，为了能取得比较好的过渡效果，我们应该适当提高pixel对texel的比例，测试下来发现一般来说3比较合适，2的话太窄，而4的话，图像放大的过大。<br>为了理解方便，我们将图像的边缘定义为暗，图像的中央定义为亮，这样明暗间隔就能产生所谓的扫面线。问题演变为在一个纹素所对应的所有像素中，如何找到一个亮与暗的分布，从而表现出一个荧光格子的效果<br>如果单纯的亮度从中心开始，依照切比雪夫距离向边缘递减，效果其实不太理想，纹素与纹素之间割裂的依旧生硬<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/cos_sum_tween.png" alt title><br>所以我们想找到一种方式柔滑这一过程，首先可以尝试用高斯平滑来处理<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/gaussian_smooth.png" alt title="不过作用效果还是在一个纹素内，所以还是不够好"></p><p>卷积核<br>简单的过渡不够，所以需要找到一个卷积核（kernel）来将像素周围的情况考虑进去，最常见的低通滤波器就是高斯滤波器（Gaussian Filter）但直接使用的话，会造成画面均匀平滑。Themaister提供了一个很好的思路（虽然由于git目录失效，原始的代码已经不可考，但是我还是在网上找到了一个<a href="https://searchcode.com/codesearch/view/26809099/" target="_blank" rel="noopener">GLSL版本</a> ），效果如下图所示：<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/dotnbloombig.png" alt title="除了有些恼人的小黑边，但是总体效果非常接近我想要的最终效果"><br>他的思路简单概述起来就是，一组像素（如4x4）向所在纹素的相邻8个纹素取样，权重为该像素到纹素距离倒数的负相关。本质上是一个非对称的低通滤波器。它的优势在于，针对每个纹素内的像素，所采样的纹素是一致的（保留了像素的质感）而在纹素内部，利用非对称的卷积核实现亮度的变化。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/9pixel_neighbours.png" alt title="一个纹素被分为9个像素"><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/sample_weight.png" alt title="取左上角的像素进行演示，红色的线条的长度与权重成负相关"><br>我们知道越靠近中间，加权值越高，对于一个靠左下角的像素来说，将其卷积核画出来可能会像这样：<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/euclid_kernel_squared.jpg" alt title="权重为Exp(-2.05 * 平方欧氏距离)"><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/euclid_kernel.jpg" alt title="权重为Exp(-2.05 * 欧氏距离)"><br>之所以不选择平方欧氏距离，是因为这会造成加权之后，中间亮度区分不开来，而周围的亮度又太低，会有种硬分割的感觉。<br>在对周围的采样做了积分之后可以得到下图。虽然和前面的图很像，这张图的意义和刚才的并不一样，它代表的是一个纹素内的亮度分布（假设亮度的原始分布均匀）。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/low-pass_filtering.jpg" alt title><br>考虑到以上的操作局限在一个很小的范围内，所以我们可以将其离散化后观察<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/after_discretization.jpg" alt title><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/top_view_discretization.jpg" alt title="从顶部看会更直观"></p><h3 id="一些细节"><a href="#一些细节" class="headerlink" title="一些细节"></a>一些细节</h3><h4 id="滤波器的构成"><a href="#滤波器的构成" class="headerlink" title="滤波器的构成"></a>滤波器的构成</h4><p>Themaister的方法中，考虑了亮度对像素最终颜色的影响，这个滤波器由两个函数构成，一个是空间域上的滤波器系数，另一个是值域（亮度）上的系数。如果采样点上的亮度越亮，意味着它将会更多的侵蚀着其他的像素。有关Glow效果，可以参考<a href="http://www.gamasutra.com/view/feature/130520/realtime_glow.php" target="_blank" rel="noopener">这篇文章</a><br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">color_bloom</span><span class="params">(float3 color)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// const float3 gray_coeff = float3(0.30, 0.59, 0.11);</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">float</span> shine = <span class="number">0.25</span>;</span><br><span class="line">    <span class="keyword">float</span> bright = Luminance(color);<span class="comment">//dot(color, gray_coeff);</span></span><br><span class="line">    <span class="keyword">return</span> lerp(<span class="number">1.0</span> + shine * <span class="number">0.5</span>, <span class="number">1.0</span> - shine, bright);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这里我们除了可以自己定义gray_coeff以外，我们也可以使用unity中的内置函数，它对应的 <code>gray_coeff</code> 为fixed3(0.22, 0.707, 0.071)<br>另外，通过在lerp的时候增加一个系数，我将暗部的亮度稍微提高了下，弥补曝光不足的情况。</p><h4 id="No-的偏移"><a href="#No-的偏移" class="headerlink" title="No.的偏移"></a>No.的偏移</h4><p>刚才的卷积核只是一个理想状态的演示，实际上，由于任意两个纹素是相邻的，所以只能在一个纹素的两边（看成一个正方形）上进行边的绘制。否则，两个相邻纹素在交界处都绘上黑边会导致扫描线过粗。另外，如果直接采样，将会出现平顶的情况，也即是当边上为偶数个像素的时候，中间会出现高度一样的状况。于是需要对之前的pixel_no进行偏移，偏移之后将会打破原有的平衡，找到一个新的中心。这里的偏移值应该小于1/(column * 2)，否则循环周期将会出问题。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> delta = dist(frac(pixel_no + float2(<span class="number">-0.125</span>, <span class="number">0.125</span>)), offset + float2(<span class="number">0.5</span>, <span class="number">0.5</span>));</span><br></pre></td></tr></table></figure></p> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/before_offset.jpg" alt title> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/after_offset.jpg" alt title><p>通过对比可以看出，偏移之后，左侧和上侧的亮度明显变暗，亮度会表现的更集中在中间的一个点。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/different_subdivision_level.png" alt title="图所示为不同粒度下的表现"></p><h4 id="采样的偏移"><a href="#采样的偏移" class="headerlink" title="采样的偏移"></a>采样的偏移</h4><p>为了给物体增加一些投影，特别是文字，会对当前像素点的周围采样。我们并不是直接用相邻像素采样（相邻像素很有可能来自于同一纹素，所以采样没有意义），而是偏移一段距离，这和ps中的投影是一个原理。只是这里需要特别注意一个问题，也即是之前看到的一张图中出现的黑边问题。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/dotnbloombig.png" alt title="注意人物轮廓周围的小黑边"><br>这个问题的起因是：如果采样点之间始终距离为一个纹素的时，虽然能保证取到的都是周围的纹素，但当图像中文本的边界正好是处于格子的边缘（也就是亮度最低的位置）在经历一个周期后，亮度是最低的地方（周期性所致）就会对之前还在暗色边界范围内的像素采样，这样就会出现在一个白的背景上出现了一条黑边。<br>解决方法就是将采样偏移限制在纹素所包含的像素个数之内，虽然这意味着我们的投影无法超过一个纹素，但是起码会避免一些比较糟糕的情况。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/problem_of_blackline.png" alt title><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/problem_of_blackline_solved.png" alt title></p><h4 id="欧氏距离与曼哈顿距离的选择"><a href="#欧氏距离与曼哈顿距离的选择" class="headerlink" title="欧氏距离与曼哈顿距离的选择"></a>欧氏距离与曼哈顿距离的选择</h4><p>前面在谈到权重的时候，我们的图示标注出来的是欧几里得距离，那么如果为了将指令减少几条，变成曼哈顿距离如何呢？结果是：并不好<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/euclid_dist.jpg" alt title="可以看出，形成了一个明显的十字亮斑，并且高度差异并区分度不高"><br>另外值得一提的是，由于编译器和显卡的优化，使用曼哈顿距离并不能节省什么开销。<br><br></p><h2 id="增加bloom"><a href="#增加bloom" class="headerlink" title="增加bloom"></a>增加bloom</h2><p>Bloom能起到加光晕的效果，能进一步降低粗糙感。通常来说，bloom只是作为HDR的一环，过程还可以包括Tone Mapping、Bright Pass Filter以及Blur。但由于我们这里只考虑2D的情况，更多时候HDR可以由美术手工实现，所以我们先不讨论ToneMapping而简单实现Bright和Blur。</p><p>1    混合横向的bloom和纵向的bloom<br>比较常见的bloom中的blur过程分为两次，一次横向像素上的模糊，一次纵向像素上的模糊，两次叠加。但是我们为了省力，也可以在一个pass中进行，毕竟我们只是为了虚化边缘，制造投影的效果。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">fixed4 <span class="title">Pass_SimpleBloom</span><span class="params">(float2 uv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    float4 sum = float4(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">    float4 bum = float4(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">    </span><br><span class="line">    float2 glareSize = float2(<span class="number">1.0</span> / <span class="number">512</span>, <span class="number">1.0</span> / <span class="number">384</span>) * <span class="number">0.65</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> height = <span class="number">3</span>;</span><br><span class="line">    <span class="keyword">int</span> width = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = -width; i &lt; width; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = -height; j &lt; height; ++j)</span><br><span class="line">        &#123;</span><br><span class="line">            sum += tex2D(_MainTex, uv + float2(i, j) * glareSize);</span><br><span class="line">            bum += tex2D(_MainTex, uv + float2(j, i) * glareSize);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    fixed4 color = PREVIOUS_PASS(uv);</span><br><span class="line">    color = (sum*sum*<span class="number">0.001</span> + bum*bum*<span class="number">0.0080</span>) * _Amount / ((<span class="number">2</span>* height +<span class="number">1</span>) *(<span class="number">2</span>* width +<span class="number">1</span>)) + color*_Power;</span><br><span class="line">    <span class="keyword">return</span> color;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="renderTexture与multipass"><a href="#renderTexture与multipass" class="headerlink" title="renderTexture与multipass"></a>renderTexture与multipass</h3><p>Bloom的操作我并没有在ppsspp模拟器中实施，主要原因是我不知道如何在ppsspp中实现真正的multi-pass shader，如果只是通过宏将pass折叠起来，由于bloom需要对周围采样，将会导致计算量指数式上涨。<br>但是这一切在unity中就很容易解决了，只需要在第一遍的pass中将bloom后的输出输出到render texture就可以被后面的shader所利用，两者加起来的时间测试下来大概只有single-pass的1/5，优化效果还是非常明显的。<br><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">RenderTexture rtTemp = RenderTexture.GetTemporary(src.width, src.height);</span><br><span class="line">Graphics.Blit(src, rtTemp, _Material_1);</span><br><span class="line">Graphics.Blit(rtTemp, dst, _Material_2);</span><br><span class="line">RenderTexture.ReleaseTemporary(rtTemp);</span><br></pre></td></tr></table></figure></p> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/performance_single.png" alt title="优化之前几乎所有的时间都耗在了最后一个drawIndexed上"> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/performance.png" alt title><p>可以看出分割出两个pass之后开销一下平衡很多。另外，unity中在利用RenderTexture.GetTemporary时，内部会调用<a href="https://docs.unity3d.com/ScriptReference/RenderTexture.DiscardContents.html" target="_blank" rel="noopener">DiscardContents</a> ，因而对CPU的效率也有所提升。详情可以参考<a href="https://docs.unity3d.com/ScriptReference/RenderTexture.GetTemporary.html" target="_blank" rel="noopener">官方文档</a>。<br>增加了bloom之后的效果图。<br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/3xScaled.png" alt title><br> <img src="https://imgs-1259535704.cos.ap-guangzhou.myqcloud.com/blog/crt/result.jpg" alt title><br><br></p>]]></content>
      
      
      <categories>
          
          <category> Dev </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graphics </tag>
            
            <tag> shader </tag>
            
            <tag> game </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
